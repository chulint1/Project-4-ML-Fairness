{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf490b6",
   "metadata": {},
   "source": [
    "# Algorithm: Handling Conditional Discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0f3ea",
   "metadata": {},
   "source": [
    " ## Step 1: Data cleaning and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ee6fa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  c_charge_degree  race  sex  priors_count  decile_score  is_recid  \\\n",
       "1   34                0   0.0    1             0             3         1   \n",
       "2   24                0   0.0    1             4             4         1   \n",
       "3   23                0   0.0    1             1             8         0   \n",
       "6   41                0   1.0    1            14             6         1   \n",
       "8   39                1   1.0    0             0             1         0   \n",
       "\n",
       "   two_year_recid  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "6               1  \n",
       "8               0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "df = data[['age', 'c_charge_degree', 'race', 'sex', 'priors_count', 'decile_score', 'is_recid', 'two_year_recid']].copy()\n",
    "\n",
    "# Encode categorical variables using DataFrame column assignment to avoid DeprecationWarning\n",
    "df['race'] = df['race'].map({'African-American': 0, 'Caucasian': 1})\n",
    "df['sex'] = df['sex'].map({'Male': 1, 'Female': 0})\n",
    "df['c_charge_degree'] = df['c_charge_degree'].map({'F': 0, 'M': 1})\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69285fc3",
   "metadata": {},
   "source": [
    "## Step 2: Applying Handling Conditional Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b354174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import accuracy_score, brier_score_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce144156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 2.2975988388061523 seconds\n",
      "Accuracy: 0.5300813008130081\n"
     ]
    }
   ],
   "source": [
    "class FairLogisticRegression(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, lambda_=0.1):\n",
    "        self.lambda_ = lambda_  # Regularization parameter for the fairness constraint\n",
    "    \n",
    "    def fit(self, X, y, sensitive_features):\n",
    "        n_features = X.shape[1]\n",
    "        initial_weights = np.zeros(n_features + 1)  # Including the intercept\n",
    "        \n",
    "        # Objective function to minimize: Logistic loss + fairness constraint penalty\n",
    "        def objective(weights):\n",
    "            scores = np.dot(X, weights[1:]) + weights[0]\n",
    "            predictions = 1 / (1 + np.exp(-scores))\n",
    "            \n",
    "            # Logistic loss\n",
    "            logistic_loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
    "            \n",
    "            # Fairness constraint: Difference in FPR between subgroups\n",
    "            mask_sensitive = sensitive_features == 1\n",
    "            mask_nonsensitive = ~mask_sensitive\n",
    "            fpr_sensitive = np.mean((predictions > 0.5) & (y == 0) & mask_sensitive)\n",
    "            fpr_nonsensitive = np.mean((predictions > 0.5) & (y == 0) & mask_nonsensitive)\n",
    "            fairness_penalty = np.abs(fpr_sensitive - fpr_nonsensitive)\n",
    "            \n",
    "            return logistic_loss + self.lambda_ * fairness_penalty\n",
    "        \n",
    "        # Minimize the objective function\n",
    "        result = minimize(objective, initial_weights)\n",
    "        self.weights_ = result.x\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        scores = np.dot(X, self.weights_[1:]) + self.weights_[0]\n",
    "        predictions = 1 / (1 + np.exp(-scores))\n",
    "        return np.vstack([1-predictions, predictions]).T\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X)[:, 1] > 0.5).astype(int)\n",
    "    \n",
    "    \n",
    "# Train the model with fairness consideration\n",
    "start_time = time.time()\n",
    "fair_lr = FairLogisticRegression(lambda_=0.1)\n",
    "fair_lr.fit(X_train.values, y_train.values, sensitive_features=X_train['race'].values)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = fair_lr.predict(X_test.values)\n",
    "y_proba = fair_lr.predict_proba(X_test.values)\n",
    "print(f\"Training Time: {training_time:} seconds\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f2d45",
   "metadata": {},
   "source": [
    "### Step 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92af6484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Subgroup 1: 0.4761255115961801\n",
      "Accuracy Subgroup 2: 0.6096579476861167\n",
      "Accuracy Disparity: 0.1335324360899366\n",
      "FPR Subgroup 1: 0.0\n",
      "FPR Subgroup 2: 0.0\n",
      "FPR Disparity: 0.0\n",
      "Calibration Disparity: 0.0\n"
     ]
    }
   ],
   "source": [
    "def evaluate_fairness(y_true, y_pred, sensitive_features, y_proba):\n",
    "    # Separate the data into subgroups based on the sensitive attribute\n",
    "    subgroup_1_mask = sensitive_features == 0\n",
    "    subgroup_2_mask = sensitive_features == 1\n",
    "\n",
    "    # Calculate accuracy for each subgroup\n",
    "    accuracy_subgroup_1 = accuracy_score(y_true[subgroup_1_mask], y_pred[subgroup_1_mask])\n",
    "    accuracy_subgroup_2 = accuracy_score(y_true[subgroup_2_mask], y_pred[subgroup_2_mask])\n",
    "\n",
    "    # Calculate FPR for each subgroup\n",
    "    fpr_subgroup_1 = np.mean((y_pred[subgroup_1_mask] == 1) & (y_true[subgroup_1_mask] == 0))\n",
    "    fpr_subgroup_2 = np.mean((y_pred[subgroup_2_mask] == 1) & (y_true[subgroup_2_mask] == 0))\n",
    "\n",
    "    # Calculate disparities\n",
    "    accuracy_disparity = np.abs(accuracy_subgroup_1 - accuracy_subgroup_2)\n",
    "    fpr_disparity = np.abs(fpr_subgroup_1 - fpr_subgroup_2)\n",
    "\n",
    "    # Calibration\n",
    "    fraction_of_positives_subgroup_1, mean_predicted_value_subgroup_1 = calibration_curve(y_true[subgroup_1_mask], y_proba[subgroup_1_mask][:, 1], n_bins=10)\n",
    "    fraction_of_positives_subgroup_2, mean_predicted_value_subgroup_2 = calibration_curve(y_true[subgroup_2_mask], y_proba[subgroup_2_mask][:, 1], n_bins=10)\n",
    "\n",
    "    calibration_disparity = brier_score_loss(y_true[subgroup_1_mask], y_proba[subgroup_1_mask][:, 1]) - brier_score_loss(y_true[subgroup_2_mask], y_proba[subgroup_2_mask][:, 1])\n",
    "\n",
    "    print(f\"Accuracy Subgroup 1: {accuracy_subgroup_1:}\")\n",
    "    print(f\"Accuracy Subgroup 2: {accuracy_subgroup_2:}\")\n",
    "    print(f\"Accuracy Disparity: {accuracy_disparity:}\")\n",
    "\n",
    "    print(f\"FPR Subgroup 1: {fpr_subgroup_1:}\")\n",
    "    print(f\"FPR Subgroup 2: {fpr_subgroup_2:}\")\n",
    "    print(f\"FPR Disparity: {fpr_disparity:}\")\n",
    "\n",
    "    print(f\"Calibration Disparity: {calibration_disparity:}\")\n",
    "    \n",
    "\n",
    "# Evaluate model fairness\n",
    "evaluate_fairness(y_test.values, y_pred, X_test['race'].values, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a974a77",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "Here's a noticeable difference in accuracy between the two subgroups, suggesting the model performs better for one group over the other, which could indicate bias. Also, the result shows signs of bias in accuracy but performs consistently across groups in terms of calibration. The zero FPR for both groups needs further investigation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
