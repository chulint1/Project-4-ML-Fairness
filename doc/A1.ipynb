{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e083dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62241329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the CSV file after re-upload and display the first few rows\n",
    "compas_data_reloaded = pd.read_csv('compas-scores-two-years.csv')\n",
    "data=compas_data_reloaded\n",
    "compas_data_reloaded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e74d9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               race      mean  median       std\n",
       " 0  African-American  5.368777     5.0  2.831122\n",
       " 1             Asian  2.937500     2.0  2.601953\n",
       " 2         Caucasian  3.735126     3.0  2.597926\n",
       " 3          Hispanic  3.463108     3.0  2.599100\n",
       " 4   Native American  6.166667     7.0  2.975389\n",
       " 5             Other  2.949602     2.0  2.350895,\n",
       "                race  two_year_recid\n",
       " 0  African-American        0.514340\n",
       " 1             Asian        0.281250\n",
       " 2         Caucasian        0.393643\n",
       " 3          Hispanic        0.364207\n",
       " 4   Native American        0.555556\n",
       " 5             Other        0.352785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate summary statistics and recidivism rates for different racial groups\n",
    "summary_stats = data.groupby('race')['decile_score'].agg(['mean', 'median', 'std']).reset_index()\n",
    "recidivism_rates = data.groupby('race')['two_year_recid'].mean().reset_index()\n",
    "\n",
    "(summary_stats, recidivism_rates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a18be6-ebc5-4bb8-8bb4-8b29343e9dc5",
   "metadata": {},
   "source": [
    "# Controling other variables the same, relation between score and race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d00607d-4b0c-4617-8b7e-3e9c93c24aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAJ1CAYAAABKLNrNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACH0UlEQVR4nOzdd3QU5dvG8WvTCRB6ERAQIaGG3kSlKPwEBZQOoVcFQXrvTZTeO6FXQZAuXXoHURCkiIgSekII6fP+wcm+RFATCJkh+/2c45HMzM7cu/vs7F4zzzxjMwzDEAAAAAAAMJWT2QUAAAAAAAACOgAAAAAAlkBABwAAAADAAgjoAAAAAABYAAEdAAAAAAALIKADAAAAAGABBHQAAAAAACyAgA4AAAAAgAUQ0AEAL5VhGGaXkCCSyvMAAADWRUAHgCSoSZMm8vHxifVf3rx5Vbx4cdWtW1cbN26M9zp79+6tSpUqxesxFy9eVMOGDWNN8/Hx0eTJk+O9/fj6448/5OPjozVr1rzwup71PF41kydPfqpN+Pr6qkqVKvrqq68UFBSU4Nv8+3uwZs0a+fj46I8//njhdV+/fl39+vVT+fLlVbBgQZUpU0bt2rXToUOHXnjdr7q4fFb/3hZ8fHxUoEABlSlTRm3atNFPP/2USNUCAJ7kYnYBAICXI3/+/Bo0aJD976ioKN24cUPz589X165dlTJlSr377rsvtYbNmzfr5MmTsaatWLFCmTNnfqnbTWjPeh6vqhUrVkh63CMgJCREZ86c0ezZs7Vr1y4tW7ZMadKkSbBtZcyYUStWrFD27NkTbJ2SdOvWLdWvX18ZM2ZUly5dlCVLFt29e1erVq1S8+bNNWnSJFWpUiVBt5kU1alTR3Xr1rX/HR4erl9//VUzZsxQixYttHnzZqVPn97ECgHA8RDQASCJSpEihYoUKfLU9PLly6ts2bJavXr1Sw/oz/KsmpB4/v76lytXTmXLlpWfn5/Gjh2r4cOHJ9i23NzcXsr7vXLlSgUFBWnz5s1KmTKlfXrlypVVt25dTZw4kYAeB5kzZ37q/SlVqpSyZ8+u1q1ba+vWrfLz8zOnOABwUHRxBwAH4+bmJldX16emr1q1Sh9++KEKFiyoChUqaPLkyYqMjPzH9YSGhmrs2LGqUqWKChYsqGLFiqlFixY6d+6cpMddqqdMmSIpdrf2v3dxv3nzpvr06aPy5cvL19dXderU0Y4dO2Jty8fHR0uWLFG/fv1UqlQpFS1aVJ06ddLt27f/8/kGBASoXbt28vX1Vfny5TVp0iRFRUXF+bn//XlMnDhRZcqUiRVkIyIiVLRoUdWvXz/WeuvWratevXpJkqKjozVr1ixVrlxZBQsW1P/+9z8tWrToqXq3b9+uWrVqqVChQipXrpyGDx+ukJAQ+/zJkyercuXK2r17t6pXr25f17fffvufr8U/KVy4sN5//32tXbtWjx49sk8/duyYGjdurMKFC6tUqVLq1auX7t69G+uxv//+uzp16qRSpUqpZMmSatOmjX799VdJcbvMIC7b+Lvbt2/LZrMpOjo61nRnZ2d169ZN9erVizV9//798vPzU9GiRfX2229r4MCBCgwMtM//7bff1KlTJ5UrV05FihRRkyZNdPz4cfv8mOfh7++vqlWrqlSpUvbndOHCBbVr107FihVTsWLF1KFDB127du1f65cet7latWqpSJEi8vX1Vc2aNbVp0yb7/DVr1ih//vw6ffq06tevr0KFCqlChQqaPXt2rPUEBgaqT58+Kl26tEqWLKnRo0c/9brE15MHPZ58DXr27Km3335bBQoUUNmyZdWzZ0/du3fPvoxhGFqyZIk+/PBD+fr6qnLlypo9e3as8Rue5/0GAEdCQAeAJMowDEVGRtr/CwsL09WrV9W/f389fPhQNWvWtC87c+ZMDRgwQGXLltWMGTPk5+en2bNna+DAgf+4/p49e+qbb75R27ZtNW/ePPXu3VsXLlxQly5dZBiG6tatqzp16kh63K36ya60MW7fvq06deroyJEj6tKliyZPnqysWbOqQ4cO+u6772ItO378eEVHR2vcuHHq2bOndu/erZEjR/7n6zB58mSlTZtWU6dOVe3atTVjxgxNmjQpzs/978+jfv36euedd3Tw4EH7Ok6fPq2QkBD99NNP9jB99+5d/fTTT6pYsaIkafDgwZo0aZJq1KihGTNm6IMPPtDIkSM1depU+3rWr1+vDh06KFeuXJo6dao+//xzfffdd2rfvn2skHPr1i0NHTpUTZs21axZs5QtWzb17t1bly5d+s/X45+8/fbbioiI0JkzZyRJR48eVfPmzeXh4aEJEyaob9++OnLkiJo2barQ0FBJjw+u1K1bV5cvX9agQYM0ZswYBQYGqnnz5nEKXXHZxrNUqFBBoaGhqlevnubOnauzZ8/aD7qUK1dOzZo1sy+7Z88etW7dWqlTp9b48ePVo0cP7dy5U506dZL0eHyBWrVq6dq1a+rfv7/GjBkjm82mZs2a6ciRI7G2O378eLVq1UrDhw9XmTJldOXKFTVo0EB37tzRqFGjNGLECF27dk0NGzbUnTt3/rH+JUuWaODAgXrvvfc0c+ZMjR49Wq6ururRo4f+/PNP+3LR0dHq3LmzqlWrplmzZql48eIaM2aM9u7da5/funVr7d69W927d9dXX32lkydPxgr6/yY6OjrWPiIkJEQ//vijhg0bppQpU+q9996TJD169EhNmzbVpUuXNGjQIM2dO1eNGzfWhg0bNG7cOPv6xo0bpxEjRqh8+fKaPn266tatq/Hjx2vatGkv9H4DgEMxAABJTuPGjQ1vb++n/vPx8TGqV69ubN682b5sUFCQUbhwYWPgwIGx1rFy5UrD29vbuHDhgmEYhtGrVy+jYsWKhmEYRlhYmNGyZUtj48aNsR4zb948w9vb2wgICDAMwzAmTZpkeHt7x1rG29vbmDRpkmEYhvH1118bBQoUMH7//fdYyzRr1swoV66cERUVZX9Mw4YNYy3Tu3dvo0iRIv/4Gly7ds3w9vY2WrZsGWv6iBEjjCJFihj379+P83P/+/PYsGFDrOc5efJk45NPPjF8fHyMvXv3GoZhGOvWrTMKFChgPHjwwLh8+bLh4+NjzJw5M9Z2xo8fbxQqVMi4e/euER0dbbz77rtGq1atYi1z4MABw9vb29i1a1esWg4cOGBf5vr164a3t7cxd+7cf3w9nvVePGn37t2Gt7e3/T2tX7++8dFHHxmRkZH2ZS5fvmzky5fPWLx4sWEYhjFq1CjD19fXuHnzpn2ZgIAAo0KFCsaOHTvs78Hq1asNwzCM1atXG97e3sa1a9fivI1/snjxYqNYsWL2tl2sWDGjQ4cO9tc/Rq1atYyPP/441rQtW7YYVapUMW7cuGF88cUXRqlSpYygoCD7/IiICON///ufUadOHcMw/r8tdevWLdZ6unbtapQtW9Z48OCBfdq9e/eM4sWLG6NGjfrH2r/88kvj66+/jjXtp59+Mry9vY3169fHeq1WrlxpXyYsLMwoVKiQMXToUMMwDGPXrl2x2oZhGMbDhw+N0qVL2z+r/+RZ+wdvb2+jYMGCRvPmzY2zZ8/alz179qzRsGFD4+rVq7HW0a5dO6NKlSqGYRhGYGCgUaBAAWPkyJFPPdcWLVoYhvFi7zcAOArOoANAElWgQAF98803+uabbzR16lR5e3srZ86cGj9+vD744AP7cidPntSjR49UqVKlWGfTYkaB3r9//1PrdnNz09y5c1WtWjXdvHlTR48e1YoVK7Rr1y5Jj7t8x8WRI0dUtGhRvf7667Gm16hRQ7du3dLly5ft0/5+rWzmzJljdcf+J9WqVYv1d5UqVRQSEqJTp04913OXHp9tdnZ21oEDByRJBw8eVOXKlZUrVy4dPXpU0uMzt6VKlVKKFCl06NAhGYbxzO2EhYXp+PHjunz5sm7cuPHUMiVLllSKFCmequXJ1yNm0L0nu8K/iEePHun06dMqX758rJ4Yr7/+ut588017LcePH1eRIkWUIUMG+2MzZsyoXbt2/eco4nHdxj/x8/PTvn37NGXKFPn5+em1117Ttm3b1KpVK40aNUrS48swfv75Z73//vuxHvu///1PW7duVaZMmXTkyBFVrFgxVrduFxcXffjhhzpz5owePnxon+7t7R1rPYcOHVLp0qXl4eFhrz9FihQqUaKEvW08S+/evdWjRw89ePBAZ86c0fr167VkyRJJT392ihYtav+3m5ub0qZNa3+fjx07JldX11hjSXh6eqp8+fL/+trFqFevnr755hutWrVKQ4YMUapUqVSuXDlNnjxZ+fLlsy+XL18+LV26VNmyZdO1a9e0d+9ezZs3T5cvX7bXe+rUKUVERKhy5cpPPdd58+a98PsNAI6CQeIAIIlKnjy5ChUqJEkqVKiQihYtqpo1a6ply5b69ttvlTZtWknS/fv3JUlt27Z95npu3rz5zOl79+7VyJEjdfnyZSVPnlw+Pj5Knjy5pLjfMzwwMFDZsmV7anrMyNFP3vorWbJksZZxcnKK03b+Pgp1zPN+8hrk+D73VKlSqWjRojp48KCqVKmi06dPq1u3bgoICNDhw4cVHR2t/fv3q0OHDpL+/zX+8MMPn7m+gIAA++jpQ4YM0ZAhQ/6zlidfDyenx8fb4/q6/1MN0uOwHxQUpOjoaM2ePfupa54lyd3dXdLj5/Ws9y8u4rqNf5MsWTJVrlzZHgqvXr2qfv36yd/fX7Vq1VKqVKlkGIbSpUv3j+sIDAx85kjl6dOnl2EYCg4OjjXtSffv39emTZue2aU8pp09y++//66BAwfq0KFDcnFxUa5cueTj4yPp6ffQw8Mj1t9PtvvAwEClTp3a/v7HePKAyb/JmDGjfR/h6+urN954Q82bN1fnzp01e/Zs2Ww2+7L+/v6aOXOm7t27p/Tp06tAgQJKliyZHjx4YH8t/u15J8T7DQCOgIAOAA4iXbp0GjhwoDp27KgRI0Zo7NixkiQvLy9J0pgxY5QzZ86nHves8PL777+rQ4cO9mtoY26jtWTJEvv1sXGRKlWqZw70duvWLUlKkFt+/f3+3jHbS5cunf3sX3yee4zy5ctr8eLFOn78uFxdXVWoUCEFBATom2++0ZEjR3Tv3j1VqFBB0v+/xgsWLLAfxHhSzG3CpMfX9pcqVeqpZVKlSvXfT/YFHDhwQJ6enipQoIAiIiJks9nUvHnzZx5UiDk4kDJlymdea37w4EFly5YtVsD7u+TJk8dpG38XFRWlypUr6+OPP7ZfRx4jR44c6tevnz7++GNdvHhR5cuXl81me6rG8PBwHTx4UL6+vnFqg/90oCZlypR666231KJFi6fmubg8+ydWdHS02rZtK1dXV61cuVL58+eXi4uLLl68+NS4C/8lTZo0unfvnqKiouTs7GyfHhOW46t06dLy8/PTokWLtHLlSvugh+vXr9eoUaPUrVs31alTxx7Cv/jiC/uYBTFt/O7du8qVK5d9nX/99ZeuXr2qggULPtf7DQCOhi7uAOBAqlSponfeeUcbNmzQ4cOHJT0ewdvV1VUBAQEqVKiQ/T9XV1eNHTtWf/zxx1Pr+emnnxQWFqZ27drFusd1TDiPOcP39zN7f1eyZEmdPHnyqVGvv/vuO2XIkEE5cuR4oef7ZE0xNm7cqGTJkqlw4cJxfu7Peh4VKlRQQECAVqxYoWLFisnV1VWlS5dWZGSkJk6cKG9vb3vX/ZIlS0qS7t27F2s79+/f14QJE3T//n3lypVL6dKl0x9//BFrmcyZM2vs2LE6e/bsC78W/+TcuXPavn27ateuLXd3d6VIkUL58+fX5cuXY9WSJ08eTZkyxd52SpQooVOnTsUaEO3u3btq06bNUyPx/11ct/F3zs7Oypgxo1avXh1rBPEYV65ckfS4O3ry5MmVL1++p2rZt2+f2rZtqxs3bqhkyZLatWuX/Uyw9PggwMaNG1WoUCG5ubn943MoVaqULl68qHz58tnrL1iwoObPn69t27Y98zH37t3TlStXVKdOHfn6+tqD/A8//CBJ8RqBvWzZsoqMjNT27dvt08LDw1+ou3jnzp2VPn16jRs3zv76Hj9+XClTplTbtm3t4fzhw4c6fvy4vV5fX1+5uro+9VovWLBAX3zxhTw8PJ7r/QYAR8MZdABwMH379lWNGjU0fPhwffvtt0qTJo1at26tiRMnKjg4WKVLl1ZAQIAmTpwom82mvHnzPrWOAgUKyMXFRaNHj1bLli0VHh6uNWvWaPfu3ZL+/1romLNqGzZsUOHChZ+61rxFixb67rvv1KJFC33++edKkyaN1q5dq0OHDmnkyJH/GfDj4vvvv1emTJn01ltvad++fVqxYoW++OILpUiRQpLi9Nyf9Ty8vb2VNWtWbdu2Td26dZP0uHtvnjx5dOLECbVr185eg7e3t2rUqKEBAwbo+vXrKliwoK5cuaLx48crW7Zsypkzp5ydndWlSxcNHDhQzs7OqlixooKCgjRt2jQFBASoQIECL/xaSI+vFZYeH0R5+PChzpw5o/nz5ytnzpz64osv7Mt17dpVbdu2Vbdu3VSjRg1FRUVp3rx5On36tD777DNJUvPmzbV27Vq1atVKn376qdzd3TVz5kxlzJhRH3/8cazu4c8Sl208S//+/dWkSRPVqlVLTZs2Vb58+RQdHa2jR49q/vz5atCggXLnzi1J6tSpkz777DN17txZtWrV0t27dzV27FhVrFhR+fLl0+eff64ffvhBTZs2Vdu2beXm5qbFixfr2rVrmjNnzr/W3759ezVo0EDt2rVTw4YN5e7urhUrVmj79u2x7hTwpHTp0ilr1qxasmSJMmfOLC8vL+3bt08LFiyQpDiNqxCjbNmyevvtt9W/f3/duXNHWbNm1cKFC3X37t1/7db/b1KkSKEuXbqoX79+Gj9+vIYOHSpfX18tW7ZMo0aNUsWKFXXz5k3NnTtXt2/ftvfsSJs2rZo2baoFCxbIzc1NZcqU0ZkzZ7R48WJ17dpVLi4uz/1+A4AjIaADgIPJlSuXmjRponnz5mnx4sX2a04zZMigpUuXas6cOUqVKpXKli2rrl27PvOeyDly5NDYsWM1ZcoUffbZZ0qVKpWKFCmiRYsWqUmTJjp27Jh8fHxUpUoVrVu3Tr1791adOnU0ePDgWOvJkCGDli1bprFjx2rEiBGKiIhQ3rx5NW3aNPstnl5U7969tWXLFs2fP18ZMmRQnz59Yt2GKy7P/Z+ex7vvvqtly5bF6pJeunRpXbhwwd69PcaXX36pmTNnavny5bpx44bSpUunatWqqXPnzvbuyXXr1lXy5Mk1Z84crVixQp6enipWrJjGjBnz1MGN5/XkvdpTp06tLFmyqFWrVmrUqJH9oIX0eCC8uXPnasqUKerUqZNcXV1VoEAB+fv72weoe+2117R06VKNHj1affr0kZubm0qVKqXRo0crderU/xnQ47KNZylYsKDWrl2rmTNnavHixbp165acnZ2VO3du9e3b135bPEmqWLGiZs6cqcmTJ6tDhw5KkyaNqlataj8YkSdPHi1dulTjxo1T3759ZbPZ5Ovrq4ULF6pEiRL/Wn/evHm1ZMkSjR8/Xj179pRhGPL29tbUqVP/tf1OmzZNI0aMUO/eveXm5qbcuXNr+vTpGjlypI4dO6YmTZr863afNGXKFI0ZM0aTJk1SWFiYqlWrpnr16v1nD4Z/U7t2ba1YsUKrVq1S/fr19cknn+iPP/7Q6tWrtXTpUmXKlEnly5dXo0aNNGDAAF28eFG5c+dWjx49lD59ei1btkzz5s1TtmzZ1LdvXzVq1EjS87/fAOBIbMaLjCgDAAAAAAASBNegAwAAAABgAQR0AAAAAAAsgIAOAAAAAIAFENABAAAAALAAAjoAAAAAABZAQAcAAAAAwAIc7j7oJ0+elGEYcnV1NbsUAAAAAIADiIiIkM1mU9GiRf91OYcL6IZhiFu/AwAAAAASS1wzqMMF9Jgz54UKFTK5EgAAAACAIzhz5kycluMadAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFiApQL6tGnT1KRJk1jTzp07p8aNG6tIkSKqUKGC5s6da1J1jqt27dqqVq2aateubXYpAAAAAEx0+PBhNW/eXIcPHza7lCTJMgF9/vz5mjRpUqxp9+7dU4sWLZQzZ06tXr1aHTt21MSJE7V69WqTqnQ8R48e1aNHjyRJjx490tGjR02uCAAAAIAZQkNDNWXKFN28eVNTpkxRaGio2SUlOaYH9ICAALVu3VoTJ07UG2+8EWveypUr5ebmpsGDB+vNN99U7dq11bx5c82ePdukah3PoEGD/vVvAAAAAI5h5cqVunv3riTp7t27WrVqlckVJT0uZhfw888/K1WqVPruu+80depUXb9+3T7v2LFjKlmypFxc/r/MMmXKaObMmbpz547SpUtnRskOY8CAAf84fdiwYYlcDRKLYRgKCwszbduSZLPZTNm+u7u7adt2RLQ12lpioa3R1hILbY22lpT9+eefWrVqlb2tGYahlStX6r333lOWLFlMri7pMD2gV6pUSZUqVXrmvBs3bsjb2zvWtIwZM0p63ECeN6AbhqGQkJDneqyjCA0N1fHjx5857/jx47p79648PDwSuSq8bIZhqH///jp//rzZpZgib968GjZsGD8wEgFtjbaWWGhrtLXEQlujrSVlhmFo8uTJ9nD+9+n9+/fnvf8PhmHE6TUyPaD/m9DQULm5ucWa5u7uLkkvdHQyIiJC586de6Hakrr/uoygb9++atOmTSJVg8RiGIZ9zAFHFBISonPnzvEFkwhoa7S1xEJbo60lFtoabS0pu3nzpk6fPv3U9OjoaJ0+fVo//PCD/UQq/tnfs+2zWDqge3h4KDw8PNa0mGDu6en53Ot1dXVV7ty5X6i2pG7kyJFq3Ljxv87nDHrSNHbsWFO654WGhqp169aSpDlz5pjSvuiel7hoa7S1xEJbo60lFtoabS2pyps3r3744QedOXNG0dHR9ulOTk7y9fXVu+++y/v/Hy5evBin5Swd0DNnzqybN2/Gmhbzd6ZMmZ57vTab7YUCviPw9PRU8eLFn9nNvVSpUkqbNq0JVSGxJE+ePNG3+eQooGnTpuUAkIOgrSGx0NaQWGhrSKo6duyodu3axZpms9nUsWNHU9r9qyauBzBMH8X935QsWVLHjx9XVFSUfdrBgwf1xhtvMEBcIvingeAGDx6cuIUAAAAAMFWWLFlUt25de9C02WyqV6+eXnvtNZMrS1osHdBr166t4OBg9evXTxcvXtSaNWu0YMGCp47c4OUZMmTIv/4NAAAAwDHUq1fP3pM2Xbp0qlu3rskVJT2WDujp0qXTnDlzdOXKFX3yySeaMmWKevbsqU8++cTs0hxGyZIllSxZMklSsmTJVLJkSZMrAgAAAGAGDw8Pff7558qYMaM6dOjA5RQvgaWuQR81atRT03x9fbVixQoTqkGM1atXm10CAAAAAAsoXbq0SpcubXYZSZalz6ADAAAAAOAoCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAtwMbsAWF/t2rX16NEjJUuWTKtXrza7HAAAAABIkjiDjn919OhRPXr0SJL06NEjHT161OSKAAAAACBpIqDjXw0aNOhf/wYAAAAAJAwCOv7RgAED4jUdAAAAAPD8COh4ptDQUB0/fvyZ844fP67Q0NBErggAAAAAkjYCOp6pf//+LzQfAAAAABA/BHQ80/Dhw19oPgAAAAAgfgjoeCYPDw8VL178mfNKlSolDw+PRK4IAAAAAJI2Ajr+0bBhw545ffDgwYlbCAAAAAA4AAI6/tWQIUP+9W8AAAAAQMIgoONflSxZUsmSJZMkJUuWTCVLljS5IgAAAABImlzMLgDWt3r1arNLAAAAAIAkjzPoAAAAAABYAAEdAAAAAAALIKADAAAAAGABXIMOAACAJMEwDIWFhZldRqILDQ195r8dibu7u2w2m9llAC+MgA4AAIAkISwsTLVq1TK7DFM1atTI7BJMsWbNGnl4eJhdBvDC6OIOAAAAAIAFcAYdAAAASU6pgg3l7OQ4P3UNw5Akh+rmHRUdqSM/LTO7DCBBOc5eCwAAAA7D2clFzs6uZpcBAPFCF3cAAAAAACyAgA4AAAAAgAUQ0AEAAAAAsAACOgAAAAAAFkBABwAAAADAAgjoAAAAAABYAAEdAAAAAAALIKADAAAAAGABBHQAAAAAACyAgA4AAAAAgAUQ0AEAAAAAsAACOgAAAAAAFkBABwAAAADAAgjoAAAAAABYAAEdAAAAAAALIKADAAAAAGABBHQAAAAAACyAgA4AAAAAgAUQ0AEAAAAAsAACOgAAAAAAFkBABwAAAADAAgjoAAAAAABYAAEdAAAAAAALIKADAAAAAGABBHQAAAAAACyAgA4AAAAAgAW8EgE9IiJC48ePV4UKFVS0aFE1atRIJ06cMLssAAAAAAASzCsR0KdPn67Vq1dr+PDhWrt2rXLlyqU2bdooICDA7NIAAAAAwGEsXLhQH330kRYuXGh2KUnSKxHQd+zYoY8++khvv/22cuTIod69eys4OFinTp0yuzQAAAAAcAiBgYFasWKFoqOjtWLFCgUGBppdUpLzSgT01KlTa9euXfrjjz8UFRWlFStWyM3NTfny5TO7NAAAAABwCMOGDZNhGJIkwzA0fPhwkytKelzMLiAu+vXrpy5duui9996Ts7OznJycNHHiRGXPnt3s0hKNYRgKCwszbduSZLPZTNm+u7u7ads2g5nvtZlCQ0Of+W9H4mhtHQAAvDpOnjyps2fPxpr2888/6+TJkypatKhJVSU9r0RAv3Tpkry8vDR16lRlypRJq1atUq9evbR48WLlzZs33uszDEMhISEvodKXwzAM9e/fX+fPnze7FFPkzZtXw4YNc5jgEhoaqsaNG5tdhqkaNWpkdgmmWLx4sTw8PMwuI8l78gBQSEiIoqOjTawGSRltLfE56gFe8Bl72aKjo/Xll18+c96XX36pefPmycnpleicbRrDMOKUZywf0K9fv64ePXpo/vz5KlGihCSpUKFCunjxoiZPnqypU6fGe50RERE6d+5cQpf60hiGoUePHpldhmlCQkJ07tw5hwno4eHhZpcAk5w/f15ubm5ml5HkPfkZ4zXHy0RbS3x8hzouPmMv1y+//KLg4OBnzgsODta6deue68Spo4lLG7V8QP/xxx8VERGhQoUKxZpeuHBh/fDDD8+1TldXV+XOnTshyks0Y8eONaXbc2hoqFq3bi1JmjNnjiln9xyt2++TR/97vZVJbs6O89zNvpzCDOFRhr468PiOFD4+PpxBTwRPfsZ4zfEy0dYSH2fQHRefsZfLx8dH69ate2ZIT5kypWrWrMkZ9P9w8eLFOC1n+YD+2muvSXp8VMzX19c+/cKFC8qRI8dzrdNms8nT0zNB6ktMyZMnT/RtPvlFlzZtWnZ8ieDJnZubs01uzuzskrb/747n6enJZywRPPkZ4zXHy0RbS3wEBMfFZ+zl69Onj/r16/fU9L59+ypFihQmVPRqiesJKMvvxXx9fVWiRAn16tVLhw4d0m+//aYJEybo4MGDatu2rdnlAQAAAECSV7RoUeXPnz/WtAIFCqhw4cImVZQ0WT6gOzk5adq0aSpTpoz69OmjWrVq6dChQ5o/f76KFClidnkAAAAA4BAGDBhgPxPs5OSk/v37m1xR0mP5Lu6SlCpVKg0aNEiDBg0yuxQAAAAAcEipUqVS/fr1tXLlStWrV0+pUqUyu6Qk55UI6AAAAAAA8zVt2lRNmzY1u4wky/Jd3AEAAAAAcAQEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAW4GJ2AQAAAEBCi4qOMLsEvGSO/B4bhqGwsDDTti1JNpvNlO27u7ubtu3EQEAHAABAknPkp+VmlwC8FIZhqHv37jp37pzZpZgif/78Gj16dJIN6XRxBwAAAIBXSFINp+AMOgAAAJKgUgUbyNnJ1ewy8BJFRUc4ZE8Jm82m0aNHm9LFPTQ0VI0aNZIkLV26VB4eHoleA13cAQAAgFeMs5OrnJ0J6EiabDabKeH4SR4eHqbXkBTRxR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAW4PK8D9yzZ48OHDigmzdvqmvXrjp37pwKFCigrFmzJmR9AAAAAAA4hHgH9EePHqlDhw46cOCAUqRIoYcPH6p169ZatmyZzp49q8WLFytPnjwvo1YAAAAAAJKseHdxHzdunH7++WfNnz9fhw4dkmEYkqSvv/5amTJl0sSJExO8SAAAAAAAkrp4B/TNmzera9euKlOmjGw2m316hgwZ9Nlnn+n48eMJWiAAAAAAAI4g3gE9KCjoH68zT5UqlUJCQl64KAAAAAAAHE28A3qePHm0fv36Z87buXMn158DAAAAAPAc4j1I3GeffabPP/9c9+/fV8WKFWWz2XT06FGtWbNGy5cv19ixY19GnQAAAAAAJGnxDujvv/++Ro8erbFjx2rPnj2SpFGjRildunQaPHiwPvjggwQvEgAAAACApC7eAf3SpUuqXr26qlevrsuXL+v+/fvy8vJSrly55OQU7x7zAAAAAABAz3ENeqtWrbR27VpJUq5cuVSsWDHlzp2bcA4AAAAAwAuId6qOjIxUmjRpXkYtAAAAAAA4rHh3cf/iiy80fPhw3b59W3ny5FH69OmfWiZLliwJUhwAAAAAAI4i3gF98ODBioqKUr9+/WSz2Z65zLlz5164MAAAAAAAHEm8A/rw4cNfRh0AAAAAADi0eAf0Tz755GXUAQAAAACAQ4t3QJeku3fvyt/fX4cPH1ZQUJDSpEmjEiVKqHnz5kqXLl1C1wgAAAAAQJIX71Hcb9y4oU8++UTz58+Xu7u78ufPLxcXF/n7++vjjz9WQEDAy6hTa9euVbVq1VSoUCF9+OGH2rx580vZDgAAAAAAZoj3GfTRo0fLxcVFmzZt0uuvv26ffu3aNbVs2VLjx4/XqFGjErTIdevWqW/fvurVq5cqVKigDRs2qGvXrsqcObOKFi2aoNsCAAAAAMAM8T6Dvm/fPnXq1ClWOJek119/XR06dNAPP/yQYMVJkmEYmjhxopo1a6ZmzZopR44c6tChg9566y0dOXIkQbcFAAAAAIBZ4n0GPSoqSmnSpHnmvLRp0yo4OPiFi3rS5cuXdf36dVWvXj3W9Llz5ybodgAAAAAAMFO8z6D7+Pho3bp1z5y3du1aeXt7v3BRT/rtt98kSSEhIWrVqpXKli2runXraufOnQm6HQAAAAAAzBTvM+jt27dXq1atdP/+fVWvXl3p06fX7du3tX79eh04cECTJk1K0AJjzsj36tVLn3/+ubp3766tW7eqffv28vf3V9myZeO9TsMwFBISkqB1JlWhoaH2f4eEhCg6OtrEahzDk685HAufscTBfg2JhbaW+PgOdVx8xhIH+7XnZxiGbDbbfy4X74Berlw5ffXVVxo9erT2799vn54+fXqNHDlSlStXju8q/5Wrq6skqVWrVvZ7sOfLl09nz5597oAeERGhc+fOJWidSVV4eLj93+fPn5ebm5uJ1TiGJ19zOBY+Y4mD/RoSC20t8fEd6rj4jCUO9msvJi6v13PdB71mzZqqUaOGLl++rMDAQKVIkUK5cuWSi8tzre5fZc6cWZKe6jqfO3du7d69+7nW6erqqty5c79oaQ7hyaNkPj4+8vDwMLEax8DRf8fFZyxxsF9DYqGtJT6+Qx0Xn7HEwX7t+V28eDFOyz1Xop4+fbqOHTtmH6jt8OHDeuedd9SuXTs1b978eVb5j/Lnz6/kyZPr9OnTKlGihH36hQsXlD179udap81mk6enZ0KVmKQ5Of3/MAWenp58CBPBk685HAufscTBfg2JhbaW+PgOdVx8xhIH+7XnF5fu7dJzBPQ5c+ZoypQpatq0qX1ajhw5VLNmTY0dO1bJkiVT/fr147vaf+Th4aHWrVtr6tSpypQpk3x9fbVx40bt379f8+fPT7DtAAAAAABgpngH9JUrV6pLly5q3bq1fVrmzJnVu3dvpU2bVgsXLkzQgC49HpguWbJkGj9+vAICAvTmm29q8uTJKl26dIJuBwAAAAAAs8Q7oAcEBKhAgQLPnFeoUCFNnTr1hYt6lhYtWqhFixYvZd0AAAAAAJgt3hfqvP766zpw4MAz5x0+fNg+qBsAAAAAAIi7eJ9Bb9iwoUaOHKnIyEi9//77Spcune7evavt27dr4cKF6t69+8uoEwAAAACAJC3eAd3Pz083btyQv7+/fZA2wzDk4uKiZs2aJfgo7gAAAAAAOILnus1at27d1LZtW506dUr379+Xl5eXfH19lSZNmoSuDwAAAAAAh/BcAV2SUqZMqXfeeUeSdPfuXcI5AAAAAAAvIM6DxF27dk3Dhg3Tjh077NO2bdumt99+W+XKldM777yjTZs2vZQiAQAAAABI6uJ0Bv3atWuqU6eOwsPDlT9/fknSpUuX1KVLF6VNm1a9e/fW5cuX1b17d2XMmFElSpR4qUUDAAAAAJDUxCmgT58+XenSpdOCBQuUIUMGSdKCBQsUFRWlsWPHqmTJkpKk8PBwzZ49m4AOAAAAAEA8xamL+8GDB9WqVSt7OJekPXv2KGPGjPZwLklVqlTR6dOnE75KAAAAAACSuDgF9Nu3byt79uz2v69du6aAgACVLl061nIpU6bUw4cPE7ZCAAAAAAAcQJwCevLkyRUYGGj/+8iRI7LZbCpTpkys5a5du6bUqVMnaIEAAAAAADiCOAX0IkWKaMOGDfa/161bJ2dnZ5UvX94+zTAMrVy5Ur6+vglfJQAAAAAASVycBolr06aNmjVrpkaNGskwDJ08eVL169dXunTpJD2+Rn3BggU6deqU/P39X2rBAAAAAAAkRXE6g168eHHNnj1bbm5uevDggVq3bq3+/fvb53fv3l2HDx/W4MGDn+r2DgAAAAAA/luczqBLUtmyZVW2bNlnzps+fbpy5swpLy+vBCsMAAAAAABHEueA/m+47hwAAAAAgBcTpy7uAAAAAADg5SKgAwAAAABgAQR0AAAAAAAsgIAOAAAAAIAFPPcgcZcuXdL+/ft18+ZNNWnSRNeuXVPevHmVIkWKhKwPAAAAAACHEO+AHhUVpUGDBmn16tUyDEM2m01Vq1bV1KlTde3aNS1evFiZM2d+GbUCAAAAAJBkxbuL+/Tp07V+/XoNHz5c+/fvl2EYkqRevXopOjpa48ePT/AiAQAAAABI6uId0FevXq1OnTqpdu3aSp06tX163rx51alTJ+3fvz8h6wMAAAAAwCHEO6Dfvn1b+fLle+a8TJkyKSgo6IWLAgAAAADA0cQ7oOfIkUN79ux55rwjR44oR44cL1wUAAAAAACOJt6DxDVr1kwDBw5URESEKlasKJvNpqtXr+rw4cOaN2+eevfu/TLqBAAAAAAgSYt3QK9bt67u3r2rGTNmaNmyZTIMQ127dpWrq6tat26thg0bvow6AQAAAABI0p7rPujt2rWTn5+fTpw4ocDAQHl5ealw4cKxBo0DAAAAAABx91wBXZJSpEihd999NyFrAQAAAADAYcUpoFeqVEk2my1OK7TZbNq+ffsLFQUAAAAAgKOJU0AvVapUnAM6AAAAAACIvzgF9FGjRr3sOgAAAAAAcGhxCuh//vmnMmTIIFdXV/3555//uXyWLFleuDAAAAAAABxJnAL6e++9pxUrVsjX1zdO16OfO3cuQYoDAAAAAMBRxCmgjxw5Uq+//rr931yPDgAAAABAwopTQP/kk0/s/65Vq5Yk6datW8qQIYMk6f79+7px44by5s37EkoEAAAAACDpc4rvA4KCgtSiRQs1adLEPu3HH3/Uxx9/rPbt2+vRo0cJWiAAAAAAAI4g3gF9zJgx+vXXX9W1a1f7tDJlymjatGn66aefNGnSpAQtEAAAAAAARxCnLu5P2rlzp3r16qUqVarYp7m5ualSpUoKCgrShAkT1KtXrwQtEnBU4VHRZpeAl8zM99gwDIWFhZm2fbOEhoY+89+OxN3dPVHHk6Gt0dYAAHET74D+8OFDeXl5PXNeunTpdO/evRcuCsBjXx24aXYJSMLCwsLs44o4qkaNGpldginWrFkjDw+PRNsebY22BgCIm3h3cS9QoIBWr179zHlr1qyRj4/PCxcFAAAAAICjifcZ9M8++0xt2rRRrVq1VLlyZaVLl053797Vjh079PPPP2vGjBkvo07AIfV6K6PcnON9HA2vkPCoaEv0lEhf/Q3ZXBynrRmGIUkO1fXWiIzW7fVXzC5DLdNmkKsjve4O2NYiDEPz7t4yuwwAeCXFO6CXK1dO06dP16RJkzRp0iQZhiGbzaZ8+fJp2rRpevfdd19GnYBDcnN2IqAjUdhcnBwqoDtOVLIeV5vNoQK6HOm5AgBeWLwDuiSVL19e5cuXV1hYmO7fv6+UKVPK09MzoWsDAAAAAMBhPPfpkkuXLmnFihVavHixHjx4oGPHjik4ODghawMAAAAAwGHE+wx6VFSUBg0apNWrV9u7t3/wwQeaOnWqrl27psWLFytz5swvo1YAAAAAAJKseJ9Bnz59utavX6/hw4dr//799sFPevXqpejoaI0fPz7BiwQAAAAAIKmLd0BfvXq1OnXqpNq1ayt16tT26Xnz5lWnTp20f//+hKwPAAAAAACHEO+Afvv2beXLl++Z8zJlyqSgoKAXLgoAAAAAAEcT74CeI0cO7dmz55nzjhw5ohw5crxwUQAAAAAAOJp4DxLXrFkzDRw4UBEREapYsaJsNpuuXr2qw4cPa968eerdu/fLqBMAAAAAgCQt3gG9bt26unv3rmbMmKFly5bJMAx17dpVrq6uat26tRo2bPgy6gQAAAAAIEmLd0CXpHbt2snPz08nT57U/fv35eXlpcKFC8caNA4AAAAAAMTdcwX06OhohYeHq0CBAkqTJo1sNltC1wUAAAAAgEOJV0DfsGGDli9frtOnTysyMlKS5OHhoWLFiqlhw4Z6//33X0qRAAAAAAAkdXEK6NHR0erevbs2bdqkjBkzqlq1akqfPr0kKSAgQEeOHFHHjh1Vs2ZNjRo16qUWDAAAAABAUhSngL506VJt2bJFvXv3VtOmTeXkFPvubNHR0Vq2bJlGjhypd955Rx9++OFLKRYAAAAAgKQqTvdBX7NmjerXr6/mzZs/Fc4lycnJSX5+fqpXr55WrlyZ4EUCAAAAAJDUxSmg//bbbypfvvx/LvfOO+/o8uXLL1wUAAAAAACOJk4B/dGjR0qVKtV/LpcmTRrdvXv3hYsCAAAAAMDRxCmgG4YhZ2fn/16Zk5Oio6NfuCgAAAAAABxNnAI6AAAAAAB4ueJ8H/TBgwcrRYoU/7pMcHDwCxcEAAAAAIAjilNAL1mypKTHXd3/TfLkyVWiRIkXrwoAAAAAAAcTp4C+aNGil10HAAAAAAAOjWvQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABbxSAf3KlSsqWrSo1qxZY3YpAAAAAAAkqFcmoEdERKh79+4KCQkxuxQAAAAAABLcKxPQJ0+erOTJk5tdBgAAAAAAL4WL2QXExdGjR7VixQqtXbtWFSpUMKUGwzAUFhZmyrbNFBoa+sx/OxJ3d3fZbDazywAAAACQxFk+oAcFBalnz57q37+/XnvttQRZp2EY8e4qHxoaqsaNGyfI9l9VjRo1MrsEUyxevFgeHh6Jtj1HPRACKSQkRNHR0Ym2Pdqa46KtIbHQ1pBYErutOaonP2O85vFjGEacTvpZPqAPHjxYRYoUUfXq1RNsnRERETp37ly8HhMeHp5g28er5fz583Jzc0u07dHWHBdtDYmFtobEQltDYknstuaonvyM8ZrHX1xeL0sH9LVr1+rYsWNav359gq7X1dVVuXPnjtdjnjxa5JW3tmxOln7pEpRhGJLkUN28jehIBf2yWpLk4+PDGXQkCtoaEgttDYmFtobEkthtzVE9+RnjNY+fixcvxmk5S6fM1atX686dO09ddz5o0CDNnTtXGzdufK712mw2eXp6xusxTk7/P56ezcnFoQK648TyZ/P09EzUnc+TbQ2OhbaGxEJbQ2KhrSGxJHZbc1RPfsZ4zeMnric7LZ0yx4wZ89SR0CpVqqhTp06qVq2aSVUBAAAAAJDwLB3QM2XK9Mzp6dKlU9asWRO5GgAAAAAAXh76AQEAAAAAYAGWPoP+LOfPnze7BAAAAAAAEhxn0AEAAAAAsAACOgAAAAAAFkBABwAAAADAAgjoAAAAAABYAAEdAAAAAAALIKADAAAAAGABBHQAAAAAACyAgA4AAAAAgAUQ0AEAAAAAsAACOgAAAAAAFkBABwAAAADAAgjoAAAAAABYAAEdAAAAAAALIKADAAAAAGABBHQAAAAAACzAxewCAAAAAOBVYhiGwsLCzC4j0YWGhj7z347E3d1dNpvtpa2fgA4AAAAA8RAWFqZatWqZXYapGjVqZHYJplizZo08PDxe2vrp4g4AAAAAgAVwBh0AAAAAntO7+bPI2enldXm2GsMwJOmldvO2mqhoQz+c/TNRtkVABwAAAIDn5Oxkk7MzHZOTtuhE2xItCQAAAAAACyCgAwAAAABgAQR0AAAAAAAsgIAOAAAAAIAFENABAAAAALAAAjoAAAAAABbAbdYAAACQ5ERFR5pdQqJyzHtTO9Z7DMdAQAcAAECSc+SnZWaXAADxRhd3AAAAAAAsgDPoAAAASBLc3d21Zs0as8tIdKGhoWrUqJEkaenSpfLw8DC5osTn7u5udglAgiCgAwAAIEmw2WwOGU6f5OHh4fCvAfAqo4s7AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABXAfdMDCwqMMSdFml5FoDMOQ9Pg+to7i8XtsPiPScdqZo7LKexxhWKPN4+XhPQaA50dAByzsqwMBZpcAB3F7/RWzS4CDmHf3ltklAABgWXRxBwAAAADAAjiDDliMu7u71qxZY3YZiS40NFSNGjWSJC1dulQeHh4mV5T43N3dTdt2+upvyObCMdukzIiMtkRPiZZpM8jVgS5jcUQRhkFPCQB4TgR0wGJsNptDhtMneXh4OPxrkNhsLk4EdCQKV5uNgA4AwD/g1xgAAAAAABZAQAcAAAAAwAII6AAAAAAAWAABHQAAAAAACyCgAwAAAABgAQR0AAAAAAAsgIAOAAAAAIAFENABAAAAALAAAjoAAAAAABZAQAcAAAAAwAII6AAAAAAAWAABHQAAAAAACyCgAwAAAABgAQR0AAAAAAAsgIAOAAAAAIAFENABAAAAALAAAjoAAAAAABZAQAcAAAAAwAII6AAAAAAAWAABHQAAAAAACyCgAwAAAABgAQR0AAAAAAAsgIAOAAAAAIAFENABAAAAALAAAjoAAAAAABZAQAcAAAAAwAII6AAAAAAAWAABHQAAAAAACyCgAwAAAABgAQR0AAAAAAAsgIAOAAAAAIAFENABAAAAALAAAjoAAAAAABZAQAcAAAAAwAII6AAAAAAAWAABHQAAAAAACyCgAwAAAABgAQR0AAAAAAAswPIB/f79+xo4cKDeffddFStWTA0bNtSxY8fMLgsAAAAAgARl+YDetWtXnT59WuPGjdM333yjAgUKqFWrVrp06ZLZpQEAAAAAkGAsHdCvXr2q/fv3a9CgQSpRooRy5cqlfv36KVOmTNqwYYPZ5QEAAAAAkGAsHdDTpEmjWbNmqWDBgvZpNptNhmEoMDDQxMoAAAAAAEhYLmYX8G+8vLxUvnz5WNM2b96s33//XW+//bZJVUlGdKRp20bi4D0GAADxZRiGwsLCEn27oaGhz/x3YnJ3d5fNZjNl22aLio42uwS8ZIn5Hls6oP/d8ePH1bdvX7333nuqVKnSc6/HMAyFhITE6zFP7uyCfln93NvGqyckJETR7Hhfuic/Y7zmicOsH3EwX2J/xmhrjsuR9ueGYah///46f/68qXU0atTIlO3mzZtXw4YNc5iQ/uR+7Yezf5lYCRLb8+7XDMOI0+fjlQno27dvV/fu3VW4cGGNGzfuhdYVERGhc+fOxesx4eHhL7RNvLrOnz8vNzc3s8tI8p78jPGaJw72a44rsT9jtDXH5Uj7c8Mw9OjRI7PLME1ISIjOnTvnMAGd/ZrjepH9Wlwe90oE9MWLF2vEiBGqXLmyxowZ88I7eldXV+XOnTtej3nyKJlX3tqyOb0SLx2ekxEdae8p4ePjIw8PD5MrSvqe/IzxmicOzmo6rsT+jNHWHJej7c/Hjh1rShd36fEBAkmmBWRH6+L+5H7t3fyvydnJ0kN74QVFRUfbe0o8737t4sWLcVrO8ilz6dKlGjZsmJo0aaK+ffvKKQEav81mk6enZ7we8+R2bU4uBHQH4unp6VA/Lszy5GeM1zxxJMT+FK+mxP6M0dYclyPuz5MnT252CUgET+7XnJ2c5OzMfs5RPO9+La4HsCydMq9cuaKRI0eqcuXKateune7cuWOf5+HhoZQpU5pYHQAAAAAACcfSAX3r1q2KiIjQtm3btG3btljzPvnkE40aNcqkygAAAAAASFiWDuiffvqpPv30U7PLAAAAAADgpeNiCQAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFiAi9kFvIqM6MjE36ZhSEZUom/XEmzOstlsibpJM95jqzAMQ2FhYYm+3dDQ0Gf+OzG5u7sneluzCiMyOvG3aRhSlJHo27UEZ1vi79dMeI+fJcJI/PfcMAw56l7dRUr0tmbGewyYKSrakJS4+1jDMBTtoJ81J1vif4c+fo8TBwH9OQT9strsEoCXwjAMde/eXefOnTO1jkaNGpmy3fz582v06NEOGdJvr79idglwEPPu3jK7BABIUD+c/dPsEpCE0MUdQCyOGE4BAAAAK7AZhmP1jThz5owkqVChQvF6nFndfq2yfTOZ3e3Y7O0nNjPbWszuyKzXm/fasbZvJrPbWmJv3+z32uztm8nR2hqQWMzer5i9fTOZvV953u3HNYfSxT2ObDabPDw8TK0hWbJkpm4fjsEKbR2JwwrvNfs1x0BbA5DUsF/Dy0IXdwAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALICADgAAAACABRDQAQAAAACwAAI6AAAAAAAWQEAHAAAAAMACCOgAAAAAAFgAAR0AAAAAAAsgoAMAAAAAYAEEdAAAAAAALMDF7AISW0REhAzD0JkzZ8wuBQAAAADgAMLDw2Wz2f5zOYcL6HF5UQAAAAAASCg2my1OWdRmGIaRCPUAAAAAAIB/wTXoAAAAAABYAAEdAAAAAAALIKADAAAAAGABBHQAAAAAACyAgA4AAAAAgAUQ0AEAAAAAsAACOgAAAAAAFkBABwAAAADAAgjoAAAAAABYAAEdAAAAAAALIKADAAAAAGABBHQAAAAAACyAgA4AAAAAgAUQ0PHCDMMwuwQAAAAAFkNOiD8COhLMsWPHdOnSJbPLABJMzJdKeHi4yZUAAPBqio6ONrsEJKK//3ay2WxmlvNKcjG7ALzaDMOQzWbTwYMH1aJFC40aNUpvvvmm2WUBL+zJtr1x40a5urrqww8/lK+vr9zc3MwuDxYS01Zu3rypkJAQ5cyZ0+ySkERER0fLySn2uZSY9gZYUUz7vHbtmh4+fKgMGTIoXbp0ZpeFRBLz/u/fv18bNmxQcHCwmjZtqgIFCsjT09Ps8l4ZNoN+B3hBp0+f1q5du5Q8eXK1adPG7HKABLNjxw516tRJpUuX1s8//6zUqVOrbdu2ql69OiEdkv7/x8j27ds1btw43blzR76+vurQoYMKFy5MkMJzezKc//nnnwoKClKuXLnY98Dyvv/+ew0dOlTR0dEyDENjxoxRuXLlzC4LiWTHjh364osvVLZsWV29elW3bt1Sv379VK1aNUJ6HBHQ8cKqV6+uX3/9Ve+9957Gjx8vNzc3jvDjlRXTdgMDA9WrVy9VrFhR9evXl2EYatOmjW7cuKEWLVoQ0mF37NgxtWnTRk2aNFHmzJk1Z84ceXl5aeDAgSpatCj7QsTbk9+hEyZM0Pbt23Xjxg2VL19evXr1UsaMGU2uEIgtps1evHhR9erVU8eOHZUuXTr98MMP2rZtmyZNmqTy5cubXSZekpj3PyQkRMOGDVPhwoXVoEEDSVKfPn20adMmDRgwQFWrVlXy5MlNrtb6uAYdz+XJ4zpr1qxRiRIldOTIEe3du1eRkZH8IMUry2az6dChQ2rfvr0CAwNVuHBh+/TJkycrU6ZMmjdvnjZu3Mi16dCVK1d048YNtWrVSl27dlWjRo20du1aBQUFaejQoTpx4gQD5CBengzn8+bN0zfffKMePXpo0aJFatCggT2cR0VFmVkmEIvNZtPp06d15MgR1a9fXy1atFCNGjXUr18/Va1aVZ06ddKePXvMLhMvic1m06lTp1S9enVduHBBb7zxhn3el19+qQ8++EDDhg3T1q1bFRwcbGKlrwYCOuIl5odmYGCgHjx4oN9++02urq6aP3++smXLpi+//FJHjhyx/3DghyleRblz59bVq1d18uTJWAMfJkuWTNOmTVO2bNk0duxYbdmyxcQqYbbAwEB98skn6t69u+7evSvp8T7Py8tLq1evVlBQkEaOHKkjR46wL8R/2rRpk6THP3QNw9CjR4+0b98+tWzZUuXLl1e+fPlUsmRJSdL69eu1b98+SXzPwhqCgoI0Y8YMDR06VH/++aekx20zTZo06tmzp6pWraquXbtq+/btJleKl+WNN95QlixZ9PPPPysgIECGYdgHCPzqq6/04Ycfqm/fvtqxYwf7rf9AQEecxRzV3717t7p166Y6deqoZcuWGjFihCIjI7Vq1Sp5enpq0KBB9pDOmXS8Cp78ooiIiFD69On13XffKUuWLJoxY4ZOnDhhn+/u7q5JkyapWLFiKlKkiAnVwipSpUqlmTNnKnPmzDp//ryuX78um82m6OhopUmTRmvWrNGVK1c0efJkhYWFmV0uLGz58uWaPn26oqOjFR0dLZvNpsjISP3555/2/VPMPElatWqV/P39JTFCMqzBy8tLrVq1Uvny5XXo0CFdvXrVvj9MmzatevbsqbfeekuDBw9WSEiI2eUiAcTsm2JOyqVKlUrTp09XiRIlNHbsWJ08eTLWIJcjR45UgwYNVLBgQfZb/4Fr0BEvu3fv1hdffKHOnTurSJEiOnz4sCZMmKCZM2eqfPnyioiIUL169fTnn39q8uTJKlWqlNklA/8q5sDTkSNHtGPHDjk5OalSpUoqWbKkbt26pdq1ayt9+vQaMGCAihYtana5MFFMW7l165Z9/IFUqVLp8OHDat++vcqVK6f+/fsrY8aM9gG+AgMDdf/+feXIkcPk6mFl9+/fV8qUKeXs7Kwff/xRvr6+kqTGjRvLMAwtWbJE0uMfws7Ozpo2bZp+/fVXjR8/3syy4cBi9od//PGHQkJClCVLFqVIkUK//PKLBg4cqOvXr+ubb77Ra6+9Zt8f3rt3T+Hh4cqUKZPZ5eMFxbz/hw4d0nfffSdPT0+VLl1alStXVnBwsFq3bq2bN29q7NixKlq0KGNTxRNn0BFn4eHh+u6779SmTRu1aNFCmTNn1jfffKNmzZopa9as+u677+Tq6qoVK1bozTffZAcMy4v5wtiyZYvatWun06dP68CBA+rVq5cOHz6sDBkyaPXq1bp9+7a+/PJLHT161OySYZKYtrJz5061bt1a9erV08CBA3XhwgWVLl1aU6ZM0b59+zR8+HDdunVLTk5Oio6OVqpUqQjn+E+pU6eWs7OzDh8+rHr16mn27NmSpJ49e+qXX35Rp06d7GfQDcPQ4cOHlTp1anOLhsN68u4Vbdq0kZ+fnzp27KgDBw4ob968Gjp0qLJmzao6deror7/+su8P06RJw2/DJCDm/d+6das+/fRTBQQE6MiRI5o0aZLWr1+vFClSaM6cOcqYMaN69eqlo0ePEs7jywDiKCQkxKhSpYqxceNGIzAw0HjnnXeM/v37G4ZhGBs3bjTKly9vXLx40eQqgfg5ceKEUapUKWP58uWGYRjGtm3bDB8fH6NixYrGnj17DMMwjFu3bhm+vr5G48aNjdDQUDPLRSKLjo62/3vbtm1GgQIFjIkTJxqTJ082PvnkE6N58+bGhQsXDMMwjAMHDhilSpUyWrZsady6dcuskvEKebJ9GYZh3Lhxw/j666+NvHnzGvPnzzcMwzA2b95slCpVyqhatarRsmVLo379+sZHH31kREREmFEyYBiGYWzfvt0oUKCAMXnyZGPv3r1G5cqVjSZNmhh79+41DMMwzp07ZzRo0MDInz+/cePGDZOrxYsKDw+P9ffp06eNt956y/7b6YcffjAKFSpkVKtWzfjmm28MwzCMBw8eGNWqVTOqV6/Ob6d4cjH7AAFeHe7u7ipQoID27t2rr7/+WhUqVNCgQYMkSSEhIXJ1deXIKF4ZxhPds9555x3Vr19fgYGBWr58uapVq6bIyEgNGjRIY8eOVbFixbRr1y4FBQXJ3d3d7NKRCP78809lyZLFftT/jz/+0OTJkzVo0CDVrVtXQUFBWr58uQIDAzVixAj169dPZcuW1dixY9W/f39FRkaa/AxgdU/e5/yvv/6yn138/PPPZbPZ9OWXX8rFxUV+fn7y9fXVggUL5OzsLC8vL7Vu3VouLi6KjIyUiws/5ZC4bt++rRkzZqhPnz7y8/OTYRiKjIzU+fPnNWXKFDk7O6ts2bIaOHCgRo0axTXnr7jRo0crf/78qlatmgzDkJOTk44ePapChQqpfv36unv3rpYsWaLKlSsrKipKM2bMUPLkyfXBBx9o1apVunv3Lr+d4om9Op4p5jq33377Tbdv39brr7+uTJkyqVixYho+fLiKFy+uzp07y9nZWZJ06dIlZc6c2eSqgbiLCV43b97U/fv3FRgYqAULFihLlizq0aOH9u7dq++//16NGjXSgAED5Ofnp7Rp05pcNRLDpEmTdPToUc2aNUvJkiWTJD148EAPHjxQqVKlFBwcrJEjR6pq1aoqXLiwRo4cqa+++kqffvqp3n77bW3evNn+OOBZYn7kStKUKVO0detWRUZG6sMPP1TDhg3VqVMnSdKwYcMUERGh5s2bq0+fPrHWERUVRTiHKaKiohQUFKS8efMqODhYo0aNUrVq1dSgQQPVrl1bU6ZM0eXLl+Xn56fZs2fbx+zAq+nWrVt688037YP+SbLfueTu3btaunSp0qdPr4EDB+rEiRNq3ry5unTpop9//lndunWTp6enmeW/ktizw27FihXKmjWrypQpIxcXF23evFkjRoxQeHi4UqZMqU6dOqlx48a6deuW5s+fr0GDBilTpky6f/++du7cqaVLlypFihRmPw3gH8WcNb9//76io6OVIkUK1a5dW4GBgbp3757Onj2rGjVqKGXKlMqQIYNKlCihUqVKqXTp0maXjkTUsGFDffDBB0qWLJmCgoLk5eWlR48e6c0331RkZKQ2b94sm82mOnXqyMfHR7Nnz9bJkyfVvXt3bdiwQcmTJzf7KcDCnjxzPmfOHC1YsECffvqpTp8+rfXr1+vOnTv6/PPP1alTJ9lsNo0aNUrBwcH6/PPPY60n5gA58LIZzxjgK3369EqWLJl27typqKgovfPOO8qWLZsKFy6sH3/8UZs2bdL//vc/pU+f3qSq8aJi3vevv/5akrRv3z7dvn1bNWvW1EcffaSAgAAFBwfr5MmTqlmzptzc3OTh4aHChQvrgw8+UPny5U1+Bq8uAjpkGIaioqI0YcIEeXl52bvVjRw5Uq1atVLRokU1bdo0TZw4UREREerSpYuyZMmiffv26dSpU/Lx8dGKFSuUJ08es58K8I9ivmh27NihqVOn6v79+8qZM6e+/PJLFSxYUN99951++uknjRw5UpK0a9cupUiRQq1atSJwOZCoqChlyJBBGTJk0MGDBzV69GgNHjxYxYoVU7du3fTaa69p8+bNKly4sHx8fBQcHKyMGTOqcePGqlixIgcp8Z9iwvmlS5d07tw5jRkzxv5DdurUqdq0aZMmT56sjh07qmPHjgoODta+ffvUoUMHBlpCoov57jx16pSOHj2qkJAQ1axZU5MnT1batGk1ffp0ZcuWTSVKlJAkJU+eXJ9++qlq1KhBr7NX3N/3NytXrtT3338vJycnffTRR8qXL5++//57Xb58WW+//bYkaefOnUqTJo1q164tLy8vM8pOEgjo0MOHD5UiRQrt2LFDderU0cCBA/XBBx+oatWqatGihSRp1qxZ6tixo6ZPny7DMFSnTh3Vr19f4eHhcnJyopsdLCvmbJXNZtPBgwfVvXt3de7cWdmyZZOzs7O961XMgarp06fr/v372r17t5YsWUI4dzBPnpXMlSuXrly5ouHDh2vgwIEqWLCgbt68qcuXL6tJkyaKiorSggULdOPGDb377rucKUKcbd26VcOGDVN0dLQaNGhgn96hQwdJ0ubNmzV16lR9+umn6tu3r1xcXGSz2bhVERKdzWbTtm3b1LdvXxUuXFiPHj1StmzZ9NFHHykwMFCnTp2yh/MJEybo1KlT6tWrF+E8CZo0aZK6dOmiQYMGKTo6Wh999JFSpEihv/76S6NHj9bDhw914MABLVmyhHD+grgPuoMLDQ3V1q1b5evrqzfeeEOhoaFq2LChzp07p3fffVezZs2KtXzHjh3166+/qkGDBqpXrx7XlcCydu7cqUqVKsWa1qdPHzk5OWnEiBGxpp87d07BwcHasGGDfv31V7m5ual3797KmzdvYpYMkz0ZfsLCwuTu7q6AgADVqVNHmTNn1sCBA1WoUCE1a9ZMhw8fVv78+XX9+nX5+/srf/78JlcPK3tWsO7Vq5fWrVunNm3aqG3btkqZMqV93vTp0zV//ny1bdtWrVq1+sd1AAktNDRUHh4e9r9///13NW/eXK1atZKfn58CAwOVLFkyubm56f79+1q9erVGjx6t3Llz686dO5o7dy77wyQgZn/zyy+/6K+//tKNGzfUsGFDSVLnzp21Z88eDRo0SB9//LFmz56tnTt3KnXq1OrcubN8fHxMrv7VR0B3cL/99pvatWun6tWrK126dHJxcVHNmjXVoEED3bx5U6NHj1bJkiVjnSFv0aKFAgMD5e/vr1SpUplYPfBsP/zwg0aMGKGFCxcqY8aMstlsioqKUvPmzeXj46P+/fsrKirKfmZ9+PDh2rdvn7Zs2aJHjx7JZrPF+oGCpC/mx8jBgwe1fft2nT9/Xj169FDhwoV18+ZN1apVSxkzZtSXX36pPHnyaOHChXJ1dVW5cuWUM2dOs8uHhT15zXlQUJDCwsKUIUMGSVK3bt108uRJNW/eXLVq1Yp1icSaNWtUs2ZNrjVHopkyZYq8vLzUuHFj2Ww22Ww2HT9+XP369dP8+fNjDQZ869YttWvXTq1bt1bq1Kl169YtFS9eXNmyZTPxGSAhxHwfbtmyRUOHDlXq1KmVOXNmjRw50t4GOnfurF27dmnYsGGqUaOGIiMjFR0dzYCACcTJ7AJgrpw5c6phw4ZauHChhgwZoocPH8rNzU2LFy9WihQpNGzYMB0/ftw+aqMk+fv7a9q0aYRzWFa+fPm0ePFiZcqUSZcvX5b0uOtypkyZtHfvXkVERMjZ2VlRUVGSpIIFC8rLy0uRkZFKliwZ4dwB2Ww2ff/992rfvr3u3Lkjb29v+xnNjBkzas2aNbp9+7b69euns2fPqnnz5vLz8yOc4189Gc5nzZqltm3bqmXLlpozZ44kaezYsSpUqJAWLlyob7/9VsHBwfbH1qpVK9Z+CnjZ7ty5o7Jly8rJycne7qKionTt2jVdu3Yt1rLh4eG6f/++wsPD9dZbb6lmzZqE8yTCZrPp6NGjGjBggHr27KmlS5dq/Pjx8vLy0v79+xUeHq4JEyaocuXK6tmzpzZt2iRnZ2fCeQIioDuggIAA/fTTT9q0aZOuXLmiPHnyyGazKXny5Lp//76uXLkiT09PrVmzRlFRURoyZMhTIZ1bqsGqoqOj7YN8Xb16Va1atdLgwYMlSW3btlVkZKRat26tiIgIe8+Qc+fOKWXKlNy72oFduXJFo0aNUr9+/TRhwgR17dpVYWFhGj9+vBYtWqR06dJp9erVOn/+vEaPHq2wsDCzS8YrICacf/3115o7d66KFy+uEiVKaMyYMVq4cKEkaeLEiSpYsKAWL16sJUuW6NGjR7HWwRl0vGwxnWkHDRqkPHny6PDhw/L399f9+/eVJ08e5c+fX8uXL9eFCxfsj8maNauyZs1qb590yH01xbxvf3//fv75Z5UvX14ff/yxnJ2dtWTJEjVo0ECtWrVS7dq1df/+fY0ZM0affPKJfHx8uPwmgTGyl4OZNWuWDhw4oLNnz9p/OLi4uKh58+Zyd3eXv7+/wsPDVa9ePeXMmVPffvut6tatq06dOmny5Mn2gUAAq4r5kjh58qQuXryojz76SJs2bdK4cePUtWtX9ezZU+PGjdMHH3ygUqVK6cGDBzp06JAWL17MmXMHFhERoddff13FihXTnTt3NGbMGJ05c0aBgYG6deuWbt++rS5dumjnzp16+PCh3N3dzS4Zr4gdO3Zo69atmj17tnx9ffX9999r2bJlGjlypIKDg9W+fXtNmDBBrVq10s8//8x+CIku5v7WTk5OCg4O1rp167Rt2za5urqqWbNmatasmcaNG6eZM2fqk08+Ufbs2bVixQpduXJFxYoVs68Dr54rV64oV65c9vcvKipKzs7Ounfvnk6dOqXZs2dr2bJlypgxo8qWLavx48erZs2aWrdunZo1a6Yvv/zS5GeQNBHQHcjo0aO1bt069e3bVzly5FDu3Lm1du1aff/995o7d66+/vprNWnSRPPnz5fNZlO9evWUI0cOrVmzRq1bt7ZfMwdYmc1m07Fjx9SmTRtNnTpV5cqVk5ubm1auXCkXFxd16tRJefPm1bx58xQYGKhMmTJpxYoVevPNN80uHSYKDw/X8ePHNXjwYB0/flxFixZVnTp11Lx5c40YMUJnzpxRaGiovXcGEFe//vqr8uTJI19fX507d07Lli1T79699ejRI02cONF+ze/cuXMVHR3NaO0whZOTkzZt2qS1a9dqypQpcnV1lb+/vySpefPm9rOo7dq1U65cuRQeHq5Zs2Ypa9asJleO5zVp0iRNmzZNtWvXVv78+VW3bl17N/UmTZro0KFD+u677/TWW2/Jz89P3t7ecnZ2VrFixehJ+5IR0B3Epk2btGXLFk2bNk2+vr726fXr19c777yjsWPHqkePHvr222+VKlUqTZo0ScHBwQoNDVWBAgW0aNEiE6sH4u7ChQtauHChGjRooLfeekuS7COPrly5UpGRkeratauGDBkiiZGRHVHMe/7XX38pKChIr7/+ugoWLKhJkybp6NGj+t///qdatWopWbJkkqR79+4pe/bsXF+H//Ss/Ymrq6ucnZ0VEBCgtWvXKl++fKpbt67OnTsnSRo+fLj++usv9ejRQ05OTrGuWwdetpg2e+PGDfn7+6tKlSpyc3PTkCFD1LdvX/n7+8swDDVr1kyVKlWyj+uSMWNGpUuXzuTq8SIMw5CLi4vOnj2r48ePa/78+WrUqJFKlSqlAgUKaPHixXJxcVF0dLSio6MVERGh6dOn6/LlyypQoIDZ5SdpBPQkLmbHe/LkSb311luxbn0R8yMgS5Ys+uKLL3Tt2jUNGjRI/v7+unv3rrZt26agoCA1a9bMxGcAxF1wcLBmzJihPXv26N1337VPz5Ahg/1ew2vXrtX9+/c1dOhQSXTLczQx+8Tt27frq6++UmhoqFxcXDRjxgxVqlRJlSpVUmBgoC5cuKDQ0FAdOHBAu3bt0vLlywlN+FdPBuuwsDC5uLjI2dnZfiD80aNHOnbsmLp27arkyZPL2dlZVatWVcOGDVW8eHH7emhnSEw2m02nTp1Sp06dlDp1alWrVs0+b+TIkerbt68WLFggm82mGjVqKF++fCZWi4RUvnx5nTlzRqVLl5aPj4+WLFmisWPHysXFRbVq1VKZMmVUpUoVTZs2TTt37pTNZtOdO3c0c+ZMBgR8yQjoSZxhGIqMjNThw4dVs2ZN+5EwJyenWD8CsmfPrkqVKmnBggUKDg7WZ599pho1aih58uRKnTq1eU8AiIcUKVKoVatWMgxD27dv15IlS+Tn5yfp8dH+hg0b6tGjR9qzZ4/u3LnD0X8HZLPZtHPnTnXp0kWffvqpfH19NWXKFHXu3FkTJ06Ut7e3fvzxR/Xs2VNeXl7y9PTU4sWLlSdPHrNLh4UZhmH/Tp03b55OnTql69evq3jx4mrUqJG8vb21adMm3bx5U6+//rqkx2PCuLi4qGTJkrLZbIqMjIx1S1MgsRQpUkSvvfaaTp8+rV27dqlevXr2HkMjR47UwIEDNWnSJLm4uKhRo0YcREoiChcuLMMwtG3bNrVp00bvvvuu9uzZo4MHD2r+/PlatWqVKlSooMKFCytnzpyqXr268uTJY9+H4eXhPugOolGjRsqVK5eGDx/+1LyYASGuXLmi2rVra+HChSpYsKAJVQLxE3M2NDAwUFFRUbLZbEqTJo3++usvjRo1SpcvX1bTpk1Vt25d+2Nu374tJycnpU2b1sTKYZZ79+6pQ4cOqlKlipo3b67bt2/Lz89PgYGBcnFx0Zw5c5Q3b15duHBByZIlU/LkyWkr+FdPnjmfOXOmZs+erZYtW+rSpUu6evWq/vzzT/n7+8vNzU1+fn7KkCGDoqKi5OTkpDVr1sjFxYVLbWAJjRo10m+//abhw4frnXfekaurq33e8OHD1aRJE+XIkcPECpFQYvZbZ8+eVb169fTpp5/q888/lyR16tRJP/30k8qUKaP9+/crICBAuXLl0vr167mrRCIhoCdxhmEoOjpaQ4YM0enTpzV69Gh5e3s/c9k1a9Zo7ty5+uabb+zXXgJWFfODdteuXZo5c6bu3bunR48eqUKFCmrTpo0iIyM1adIkXbx4Uc2aNVOdOnXMLhkW8Pvvv6thw4aaO3eu3njjDY0YMULOzs5q3bq12rZtKycnJ3Xs2FFlypSRl5eX2eXiFXLp0iWNGTNGtWrVUuXKlSVJp06d0uTJk/XXX39p7dq12r59uy5fvizDMPTZZ5/JxcXFfpAcSAwx350//vijTp48qb/++ks5cuSwj9XSoEED/fXXXxo6dKjeeuutWCEdSc+9e/f0xRdfyDAMzZ49W4MHD9a+ffu0cOFC+2CA69atU4kSJfTGG2+YXa7DoI9KEmez2eTs7KzGjRvrypUr9uvLn+Xs2bMqWLAgXZfwSrDZbPrhhx/UtWtXvffee/L391f16tW1cuVK/fTTT3rjjTfUsWNHeXt7a/LkyVq7dq3ZJcMEfz8GnTp1ahUvXlxBQUHasmWLHj58qI8++kivvfaa0qdPr19//VWjRo1SVFSUSRXjVbRp0ya1bNlSP/74Y6wDO0WKFFHLli0VGRmpQ4cOqVq1avr888/VsWNHwjlMYbPZ9P333+uzzz7T/v37devWLQ0ZMkSdOnVSVFSUli9frsyZM2vo0KHas2ePIiMjzS4ZL1GaNGnk5+enEydOqFatWjpy5IhmzJihXLlyKTo6Wm5ubqpbty7hPJGRxByEt7e3Bg4cqPXr12vUqFH68ccf7fPu3r2rSZMmacOGDWrTpg3394XlxYyt8O2336pBgwZq06aNXFxctG3bNrVo0UJ58uTR2rVrlStXLrVo0ULlypWLNQgTHEPMmaITJ05o0aJFGjVqlO7fv68ePXqoRIkS+v7775U5c2YVL15cTk5Oypgxo+bNm6dVq1YpTZo0ZpcPC/v7gZ9q1aqpWLFiunPnjo4ePaqwsDD7vDJlyig8PFznz59/aj2EcyS2S5cuaejQoWrfvr1mzZqlHj16KFmyZCpQoIACAgIkSStWrJCLi4smTJig8PBwkyvGy1a2bFmVKFFCd+7c0YgRI+yXuXLCzjyMRuJAatWqZb91xvHjx/Xaa6/ZR5mNuUYud+7cZpcJ/CebzSabzaY//vhDH3/8sYKDg1W7dm1VqFBBvXr10tq1azV69GiVKVNGBQsW1ODBg7lFlgOKOVPUp08flSlTRr///ru8vb310UcfKTo6WgEBAcqePbvCw8M1Y8YMHTlyRJ07d2bwQPyrJ685f/Dgge7evascOXJo/Pjxio6O1tatW+Xt7a33339fTk5OCgkJUYYMGRhYCZZw48YNvf766/Lz89Mff/whPz8/Va9eXX5+fhowYIDeeust1a1bV1u3btUff/whT09Ps0vGS+bl5aUyZcro6NGj9n0bvXvMRUB3IE5OTqpRo4aKFi2qH374QefPn7ePIFu0aFFlzpzZ7BKBf/T3QZScnZ3l5eWlmTNn6saNG6pcubJ69+4tSUqZMqU8PT3tyxPOHdPVq1c1duxY9e7d2z5QYGhoqNzc3HT9+nXlypVLGzdu1Pfff6+wsDDNmjVLWbNmNblqWNmT4Xzq1Knau3evfvnlF40ZM0bvv/++Jk6cqPbt22vs2LHau3ev3nzzTR06dEiPHj3S+++/b3L1gBQSEqLAwEAdO3ZMPXv2VPny5TV48GCFhobq6tWrsQbF5FZaSV/Mb6tWrVpp3bp1mj9/vkqXLk04NxkB3QHFHDkFXhUxXyBnz57VnTt35ObmptKlS6tBgwYaNmyYUqZMqYEDB9qXP3z4sNKlS6fkyZObWDXMdufOHUVERKhYsWL2aa6urrp27ZpGjRolPz8/ffjhhwoKClKRIkU4w4n/FBPOx48frxUrVuiLL75Q69atVaJECYWFhcnd3V3Tpk1Tr169tGrVKvn6+qp48eKaMWOGJM5KIXHFfHcGBwcrRYoUkqQcOXIoNDRUrVu3VtWqVTV06FBJUrJkyeTp6aksWbKYWTISmc1mk2EYcnFxUdGiRXX69GkFBQUxSKrJCOgO6smzkdzeBVYX01W5V69ecnd3l5ubm5o2barWrVvr/PnzWr16tRo0aKBChQopICBABw4c0OLFi+0/SOAY/r4ve/DggUJDQ/Xo0SP7NGdnZ2XLlk379u3TO++8owYNGphRKl4hS5YsUbVq1ezjEvzyyy/avn27pkyZohIlSujatWvavn27li1bptdee03t2rXTV199pfDwcF28eDHWgR+u6URiidkf7tmzR/PmzbMP9lWlShU1a9ZMX375pdKnT6+zZ8/Ky8tLy5cv1+XLlzVy5EizS0cii7lssH379jIMg3BuAQR0B/Xkj1jCOawuODhY/v7+6t+/v3LlyqWdO3fK399fNptNn3/+ufLmzasVK1bol19+Ufbs2bV8+XLGU3BANptNe/fu1YMHD1StWjUVL15cLi4umjp1qsaMGWPvUREZGalixYpxf3P8p/3792vp0qWqV6+efVrMmcY7d+5ox44dmjVrlkJCQuTt7a2jR49q1qxZmjx5ssaPH6+OHTtq8eLFCg0NVcOGDbmFKRKNzWbT8ePH1alTJ1WvXl1nzpzRyJEjdevWLTVr1kyhoaFavny5/P399cYbb+jRo0eaM2eOsmfPbnbpMAm9yKyDgA7AkmKO/gcEBCggIEAZM2bU22+/rUyZMtnHS5g7d64iIyPVrl07vf/++4qOjpbEWSpHFR4eru+//16rVq2SYRj68MMP9dVXX6lTp07q2rWr2rRpoxQpUmjr1q26cOGC8uXLZ3bJsLAJEyaodu3a2rhxoyTp4MGDyp07t1KmTKnw8HCNGzdOV69eVYMGDfT+++/r7bff1ty5c3XkyBGFhITI09NTkydPVosWLbRhwwbVqVOHgI6X7smeRBcvXlSrVq3UqVMnSVKPHj00Z84cSVK7du30wQcf6NKlS/Ly8lKOHDmUIUMG0+oG8P8I6AAsyWazaevWrRozZowk6fr162rdurUyZcqk1157TY0aNZLNZtOyZct09+5d9enTh2DuoGJ+kLq5ualdu3ZycXFRt27dZLPZVK1aNc2ePVtdu3ZVt27d5OrqKnd3d82ePZuzBfhHJ06c0ObNm3XixAl1795dadOmVYsWLdSsWTP16dNHs2bN0uXLl5U+fXrlyZPH/rjdu3crd+7c8vT0tF9v7u/vrxs3btBtFC9dzL7w0KFDOn36tI4cOaIiRYrY548ePVrdunWzh/SaNWsqR44cJlUL4J/YjL/fzBMALODnn3/Wp59+qjp16ih16tSaPXu2fHx8NHToUPtI23/99Zfmzp2r/fv3a8mSJXRZdlAPHjxQypQp7X//+eefmjFjhlauXKlx48apWrVqCgkJ0cWLF+Xi4qJMmTJxKzX8py1btmjJkiWSpIkTJ2r//v3q0aOHWrRoobZt2ypNmjS6cOGCdu3apUePHunMmTMKCAjQ2rVr5eLiIsMwFB0dzaBwSFTff/+9unfvrhw5cujKlSvKlCmTli9fHuvseK9evbRjxw5169bNPg4HlzsC1kFAB2A5ly5d0uHDh3Xt2jX16tVLknT27Fm1bt1a+fLlixXSAwIC5OrqSjh3UD///LM6duyoUaNGqVSpUvbp169f15QpU/Ttt99qypQp3OIKcfbkrdQ2btyoJUuWyNnZWRMnTtSBAwfUvXt3tWrVSq1atdLDhw/Vq1cvubi4KFu2bBo6dKhcXFwUGRkpFxc6KSJxhYWFafLkycqVK5dq1qyp7du3a9asWXJyctKUKVOUKVMm+7IDBgxQ69atOYMOWBABHYCp/n5HgYiICNWtW1fnz59X2bJl5e/vb1/2p59+Utu2bVWoUCH179+fLsrQ4cOHNWXKFN28eVMjRoxQiRIl7PN+/PFH++Be48ePV9WqVc0qE6+YJ/dLu3fvVu/evZU7d25NmjRJhw4dUteuXdWyZUt169ZNUVFRcnNzsz+WW6nBDGfOnFG7du2ULVs2de/e3X7AcsuWLZo7d64Mw9DUqVNjhXQA1sQFmwBM8/fbYhmGITc3N82ePVulS5fWb7/9pg0bNtgHfytYsKDmzJmjvXv3avTo0YqMjDSrdJgk5phyRESEJKl06dLq0qWLsmfPrl69eunYsWP2ZTNlyqQPP/xQ3bt3l7e3tyn14tUwd+5cnT592v73k/uWdevWyc3NTSEhIfriiy9UunRpjRs3TvPmzdOQIUMUHBxsX9YwDMI5Ek3Md6MkpU2bVkWKFNGPP/6owMBA+/QPPvhAbdq0kaurq5o0aaKAgAAzSgUQD5xBB2CKSZMm6cSJE2rfvr2yZs1q77IeE9pv3rypDh06SJJatWqlDz74wP7YX375Re7u7nrjjTdMqR3miGkbR44c0fbt2yVJjRo1Us6cOXXq1ClNmzZNFy9e1KhRo1SgQAH7iNozZsxQihQpTK4eVnXt2jU1bNhQJUqUUNu2bZU/f377vI4dO+q3337T/PnzdeLECc2dO1eurq6aMGGCdu/erRUrVmjFihVcv4tEc/z4caVMmfKZBx3/+OMPDR8+XCdPntTs2bPl6+trn7dhwwatXr1aQ4cOpfcZYHEEdACJ7sGDB/rf//6nu3fvKlOmTEqfPr2qV6+u9957L9YPh4CAALVv3142m01t27ZVlSpVTKwaZooJ51u2bFGvXr1UpEgR/fTTT3rttdc0YMAAlS5dWidPntS0adO0d+9evfnmm7p586YWLlzI7dTwn86dO6c+ffooe/bs+uKLL/Tmm2+qU6dOunLliqZNm2bfL23evFmLFy9WYGCglixZolSpUkl6ujcQ8DKsXbtWvXv3VpYsWVSpUiVVr15dBQoUiDXewfXr1zV48GCdOXNGs2fPVqFChezzgoODOVgJvAII6ABMMWHCBP3111/y8fHRL7/8ou+++06ZMmVSmTJl1KJFC6VPn17p06dXQECAOnfurFu3bqlPnz567733zC4dJjlx4oQ6dOigXr166eOPP9aVK1dUtWpVFSxYUL1791aJEiV069YtHT58WIGBgXr33Xc5U4Q4O3funP1a81u3bikoKEhTpkxRtmzZYg0ct3btWp04cUKDBg2iOzsS1apVqzRixAg1adJEGzduVEhIiPLkyaP27dsre/bssQZP7du3r86fP6/JkyeraNGiJlcOID4I6ABMcfDgQbVv315Dhw5V9erVdezYMS1ZskRHjx5VVFSUcufOLT8/P/3vf//TgwcP1L17dw0YMIDA5SAePnyoBw8eyGaz2Qc18vf318mTJzVp0iTdvHlT/fv3V/bs2XXo0CFJ0qBBg+Tr6yt3d3czS8cr7Ny5c+ratatu376tr7/+WhUrVpT0+Ay5YRj2kB6DAeGQ2D766CP5+vpqyJAhmjNnjtatW6c//vhDWbNmVYsWLVS0aFH5+Pjo3r176tixo27cuKGNGzeyXwReIQR0AKbp06ePDhw4oEWLFil79uySpPr16+v333+Xs7Ozbt++rVSpUqlbt2720biR9M2fP1+HDh3S4cOHZbPZ1KhRI3Xv3l3dunVTSEiIpk+frilTpujGjRsaPHiwzp8/r9q1ayt37tyqWrWq2rdvL4n7+uL5nD9/Xt27d1fu3LnVunVrFShQwD6PruwwS8zBoFWrVmncuHGaOHGiihYtKicnJ33zzTcaNGiQJCl9+vSqVKmSqlatqnTp0ilVqlSM3A68YhjFHYBpKlasqODgYB0+fFjS48B+48YNLVq0SAsXLtSoUaOUP39+FSlSxNxCkWjGjBkjf39/lStXToMHD1bPnj1VrVo1SVKnTp1UvXp1/fbbbzp69KhKlCghm82me/fuKW/evCpSpIhq1Kghm81GiMJz8/Hx0ddff61Lly5p1qxZOnv2rH0e7QpmiempUaJECTk7O2vt2rVydXWVs7Ozfv75Z73xxhsaPHiwfHx8tGrVKvXp00fp0qUjnAOvIM6gAzCVn5+fIiMjlSlTJp08eVJTp06NNfJsRESEXF1dTawQieW7777TpEmTNG7cOHsbiLn298lrgFevXq3Jkydr9+7dkqSxY8fq1q1bGjBggJInT25W+Uhizp07p759+ypVqlQaNGgQd42A6WJ6cMyaNUvTpk3Tt99+K39/f+3cuVMzZsxQwYIFFRoaqsDAQEVFRSlLlixmlwzgObj89yIAkLCe7CbarFkzderUSZkzZ9bs2bOVN2/eWMs+OTotkqaY9nDq1Cm99957KliwoH1aTCiP+f/+/fvl7u6uR48eqW/fvpKkbdu2adGiRYRzJKh8+fJpyJAhWrJkiXLkyGF2OYD9e7NMmTJatGiRatasqQwZMmj69OkqWLCgJMnDw0MeHh5mlgngBfHLF0CiioyMlIuLix48eKCoqCiVKFFCOXPmVJo0aeTj4/PU8nQpdQzh4eE6cOCAmjZtaj9j/vf3PiwsTBMnTpSHh4eaNWum3bt3y8vLS4sWLXrqwA6QEHx9fVWoUCHZbLZYvTgAM/n6+ur999/XsmXLNGrUKBUqVIjxEYAkhG8aAIkmKipKLi4u+uOPP1SnTh2dPHlSadOmVZs2bXTy5EkdPHjQ7BJhApvNJjc3N3l6eurChQuS9FQQio6Olru7uwoVKiRnZ2e1bNlSS5Ys0aRJkwjneKlsNtszR3AHXqbo6Oh//XfdunXl5eWl7du3S+JgNpCU8G0D4KV41vAWzs7Oun79uho3bqxixYqpfPnykh4PepMyZUrt2LFDkZGRiV0qTGYYhiIjI5UnTx6dPn1av/7661PLxISjiIgIPXr0SM7OznJ1dZWnp2dilwsHRPhBYon57oyIiLD/+8mDQzH/zp49uwoVKqT9+/crODg48QsF8NIQ0AEkuJiudmfPntWmTZt06NAhPXz4UJLUoUMHlS9fXiNHjrT/0MiRI4eaNGmihg0bcs25A7LZbHJxcVHz5s116dIlzZs3T7dv335quYiICN2/f1/FihVj4EAASU7Md+e+ffvUo0cP1apVSx9//LE2bNigO3fu2JeLjo5WihQp1LBhQ92+fVthYWEmVg0goTGKO4CXYsuWLerfv7+cnZ3l7u6ucuXKaciQIbp8+bLefPNNe8CKubcrID0eoX3QoEGqUqWKmjZtar/FXnBwsObMmaNvvvlGCxcuVK5cucwtFABegh07dqhbt25q3ry5ChcurBUrVmjfvn1avHjxU7ccDQwMVGRkpNKlS2dOsQBeCgI6gAR36dIlde7cWX5+fipbtqw2btyozZs3q2DBgurTp4+8vLwI5nim6Ohobd68WYMGDVLq1KmVK1cueXp6KiQkRBcvXtTUqVOVL18+s8sEgAQXHByszz77TG+//bbatWunmzdvys/PT1WqVFGtWrUUEhKiQoUKMWAhkMTx6QaQoH755Rd999138vb2Vq1atZQjRw59+umnql69us6ePauhQ4cqKChIzs7OsQa+AaTH11d++OGHWrNmjerWrSsXFxdFRUWpTJkyWrBgAeEcQJLy5HmyiIgIXb9+Xf/73/9079491a5dW2XKlFGPHj20fft2DRkyRBEREYRzIInjYk8ACSYqKkqzZs3Srl27lDlzZrm5uUl6HLpatWolSdq6dat69eqlr7/+WilTpjSzXFhY9uzZ1a5dO7PLAICXymaz6fjx40qdOrXeeOMNpUmTRsuXL9f333+vSpUqqV+/fpIeh3fCOeAY+JQDSDDOzs4aMmSIatSooXv37mnChAn2wWucnZ3VqlUrVahQQUFBQQoJCTG5Wljdk2eWuBoLQFIUFRWlXr16adKkSXJyclKhQoW0aNEivfHGGxoyZIj9QPfNmzeVNWtWRUVFmVwxgJeNa9ABPLeYEWcvXryoP//8UylSpFCxYsUUHBys4cOH6+zZs6pWrZpatmxp/5ERFRWloKAgpUmTxuTqAQAwT8x36Lfffit/f39NnTpVnp6e6tixo4KCglSqVCnlzZtXp0+f1pYtW7Rs2TJ5e3ubXTaAl4wz6ACeS8wPi61bt6pJkyYaOHCgGjVqpIULFypFihTq37+/8uXLp02bNmn+/PkKDw+X9PhMOuEcAOBooqOjY/UGstlskiRfX18FBwdr27ZtSpcuncaPH6+SJUvq6NGjmj9/vm7duqUlS5YQzgEHwRl0AM9tz5496tSpk3r06KHy5ctr0aJFWrhwoQYMGCA/Pz8FBwdrxIgROnDggJo3b64WLVqYXTIAAIlqxIgRKlmypKpUqSJJOn78uH799Vc1aNDAPiL7jBkztGTJEs2fP19vvvmmIiMjFRkZqYiICLm5ucnd3d3kZwEgsXAGHcBzCQsL05o1a9SuXTs1btxYyZMn17Fjx1SwYEENGzbMfia9X79+ev/99/X++++bXTIAAIkqKChIhmEoW7ZskqTw8HD5+/tr8ODBat68uZYuXapHjx7p448/Vs6cOXXixAn7Yz08PJQyZUrCOeBgOIMO4LkEBgbqo48+0hdffKE6depoxIgRioiIUJcuXTRixAht2LBBzZo1U+vWrZUuXTqzywUAIFFFRkbKxcVF4eHhcnNz0549eyRJ5cuX18WLFzV27Fhdv35dwcHB6tOnjxYsWCCbzaZFixaZXDkAM3EGHUCcPHksLyoqSqlSpVLjxo2VNm1a/fDDDwoICNB7772nVKlSycvLS2nSpNGmTZsUERFhYtUAACS+u3fvas2aNQoODpabm5vu37+vXbt2qV27dtq0aZNy586tiRMnatKkSSpfvrwWLFig0NBQHT16VGvXrjW7fAAm4j7oAP5TzIBwBw4c0O7du/XLL7+obdu2ql69urJkyaI+ffooOjpa77zzjiQpNDRUPXr0UJUqVeTp6Wly9QAAJC53d3fNmjVL27dvV82aNfXXX3/Jz89PktS1a1dFR0fro48+Us6cOTVo0CCdOXNGly5d0ty5c1W8eHGTqwdgJs6gA/hPNptN27dvV4cOHRQWFqZ06dLpypUr9q7rzs7OioyM1I8//qgJEyZo9+7d8vX1JZwDABySp6enpkyZolOnTqlbt25Kmzat8uTJozZt2qhevXrq3r27Nm3aZF++YMGC+vjjj7VmzRq9/vrrJlYOwGycQQfwlIiICLm6utr/vnXrlmbOnKmuXbuqSZMmkv7/2ro///xTXl5eOnHihD7//HO5ublp1qxZypUrl1nlAwBgKpvNJhcXFwUFBSlZsmTasmWLPvjgA2XNmlXt2rWT9PhMus1mU9WqVe2Pc3Hhpzng6NgLAPi/9u4+puq6/+P46xwOJAE6lCA7E7kx5U6NNgFHgnfTtC3Mu2pokjmEId5AabNAurHsIkBQLFOb2lSWpowZzTaHpg7UVlbepmJoqWQTQfDmwOH7+8PL87tYv9+u7VqX59B5PjZ29j3ny/e8P/xzeJ335/v5dLFy5UqdO3dOq1atcuzRarfbde3aNfXt29dxXmdnp5qampSbm6uXXnpJ06dPV2trqx555BEFBQU5q3wAAFyC1WpVZWWlbDabMjMzNW/ePK1evdoR0s1msxYtWiSz2azx48dL+t+90QG4LwI6gC4SExM1ceJEmUwmx/6sra2tstvtam1tlXTvnnQvLy95eXnJbrerrq6uSwcAAAB3c3+9ljNnzuj8+fMKCQlRRESEzGazioqKlJubq+zsbJWXl8tqtWrq1Knq1auXwsPDnV06ABdCQAfQxbBhwyRJR44cUXl5udauXasBAwYoLi5OhYWFioiIUEREhOP8oKAgx/6uAAC4o/vhfM+ePSooKJDFYtG1a9eUk5OjqVOnKiEhQcXFxcrNzdXs2bMVGRkpX19fpaeny8fHx9nlA3AhLBIHwLGF2v3H+vp6GYahkydPKisrSzabTfn5+QoPD9esWbNUUVGh3bt368MPP9SRI0c0ZswYZ5YPAIBT2O12Sfemph84cECvv/66MjIyVFNToxkzZmjDhg3atWuXWlpaFB8fr9LSUnV2dmrfvn2aMGEC4RzAn5iMf93cGIDbuv/tf01NjQoKCrRixQp5eHgoJydHERERWrVqlTw8PLRs2TJ9//33MgxDAQEBevPNNxUZGens8gEAeGB++OEHDR06VNK9RVMNw9Crr76q/v37KycnR01NTUpPT1dHR4dOnTqlnJwcPf/88+rVq5fsdrva2trUs2dPJ48CgCsioANu7J133pGHh4eWLl0qSTp16pQqKioUERGhF198UZJ0+PBhR0j/+OOP5enpqStXruihhx6Sp6en/Pz8nDkEAAAeqH379ikvL08zZ85Uenq6JKm1tVVTpkzRnDlz9Nxzz+kf//iHbDabCgoK9MYbb2jPnj2aMGGCJk+erNjYWCePAIArY4o74KZ27NihyspKpaSkSJIaGxu1ZMkSVVZWdvlWPy4uTsXFxTpz5owyMzN1+/Zt9e3bV7179yacAwDcTkhIiBITE/Xll19q/fr1kiRfX1+NHTtW/v7+qqur0+XLl5WUlCRJ8vf3l4eHh3777Td2OQHwbxHQATfV2NgoX19fRUdH6/Tp06qrq9O0adPk7e2tvXv3Os4zmUyOkF5XV6clS5aIiTcAAHdkGIZCQkKUlZWl6OhoVVZW6pNPPpEkvfbaaxozZoxqampksVg0evRoSVJbW5uysrJUUlKixx57zJnlA+gGCOiAm4qJiZGPj48mTZqkSZMmacCAAUpJSVF2dra+/vprFRQUOM41mUwaNmyYNm7cqEWLFrFPKwDALRmGIcMw1K9fP2VmZmrIkCGqqqrShg0bJN37vGxqatLFixd19uxZffDBB6qurtaIESPUq1cvJ1cPoDvgHnTATdxfBO7+o3TvHvQtW7YoLCxM1dXVkqSmpiZVV1fr/fff1/Tp05Wfn+/MsgEAcKra2lqFh4fLYrGod+/eXV67cOGC1q1bp2PHjiklJUVz587V/v379fbbb6u9vV3e3t4qKSlRVFSUk6oH0N0Q0AE3UV9fr7CwMMfxzZs3tWTJEgUEBOjYsWMKCAhQeXm5vL29HSG9sLBQTz/9tFasWOHEygEAcI7t27crLy9PgYGBMpvNGjZsmAIDAzVkyBANHDhQISEhamlpUXFxsX766SdNmTJFqampji661WpVQECAs4cBoBshoANuoKysTGvWrNGUKVMUFRWladOmycvLS+3t7fL09NSOHTv06aef6tFHH+0S0nfu3Kn169erqqpKAQEBTG0HALiV+vp6LViwQA0NDQoNDZW/v78uXryo5uZm3b17VwEBAYqPj1dLS4vq6+vV0dGh1NRUzZ4929mlA+imCOiAGygtLdW6dev0+OOP6/bt245/IOLj4xUVFaWOjg5VV1drzZo16tu3r9asWSNvb2/duHFDJpOJ++YAAG6roaFB8+bNU0hIiKZOnarExERdunRJ3333nS5fvqzDhw/r1q1bOn36tDo7O2W1WrVz504+OwH8RwjogBs4duyYVq9erfj4eA0aNEhbtmzRoUOHZLFYNHnyZCUnJys5OVm7du1SRUWF2tvbtXXrVvXo0cPZpQMA4HRnz57VwoUL5efnp+zsbCUmJjpes9lsMpvNOnPmjP744w8FBwcrNDTUidUC6M4I6IAbMAxDc+bM0c2bN/X5559Lkvbv36/a2lpt3LhRFotFycnJGjlypOrr63Xu3DkVFBTIarU6uXIAAFzD+fPntWDBAvn7++uVV17RyJEjJUl2u10eHh5dFmEFgP8UAR34m+vs7JTZbNbJkyc1ffp0ZWRkaN68eZKk+fPn6/jx40pISFBtba2uXLkiq9Wqbdu2KTAw0MmVAwDgWv41pM+ZM0fJycmSRDgH8JchoANuoqmpSQsWLJBhGFq3bp0KCgp08OBBbd68WWFhYbLZbKqsrFRCQoKCg4OdXS4AAC7pfkgPCAjQjBkzNHbsWGeXBOBvhIAOuJE9e/YoJydH/fv31507d1RWVqaYmBhHlx0AAPx758+f16xZsxQTE6Pi4mI9/PDDzi4JwN8EAR1wIy0tLcrOztbp06e1cuVKDR8+3NklAQDQLV24cEEWi0X9+vVzdikA/kZomQFupGfPnkpISNDNmzcdHXO73e7kqgAA6H5CQ0MJ5wD+cnTQATdxfwEbm82mZ599VqGhofroo4+cXRYAAACAf6KDDrgJk8kkwzBksVgUGxurhoYGtbS0OLssAAAAAP9EBx1wQ5cuXZJhGKzWDgAAALgQAjoAAAAAAC6AKe4AAAAAALgAAjoAAAAAAC6AgA4AAAAAgAsgoAMAAAAA4AII6AAAAAAAuAACOgAAAAAALoCADgAAAACAC7A4uwAAAPDfN3PmTB05cqTLcyaTST4+PgoLC1NaWpqeeeYZJ1UHAAAkAjoAAG4jKipKy5Ytcxzb7XZdvXpVGzduVE5Ojvz8/JSUlOTECgEAcG8EdAAA3ISvr6+eeOKJPz2fnJys4cOH64svviCgAwDgRNyDDgCAm/Py8pKnp6fj+M6dOyoqKtK4ceMUExOjJ598Ui+//LJOnTrV5fcOHTqk1NRUxcbG6qmnnlJ+fr6am5sdr1++fFk5OTmKi4vT0KFDNWvWLJ08efKBjQsAgO6GDjoAAG7CMAx1dHQ4ju9PcS8vL1dbW5tSUlIkSYsXL9bRo0eVm5ur4OBg/fLLLyotLdWiRYv01VdfyWQyaf/+/crIyNDo0aNVUlKi5uZmFRYWqqGhQZs2bdL169f1wgsvyNvbW3l5efL29tamTZuUmpqqHTt2KDw83Fl/BgAAXBYBHQAAN3H06FFFR0d3ec5kMmngwIEqLS3V6NGjZbPZ1NbWpry8PE2cOFGSFBcXp7a2Nq1YsULXrl1TYGCgysrKFBERofLycse1evTooeLiYjU2Nmrr1q26ceOGtm3bJqvVKklKSkrSxIkTVVpaqrKysgc3cAAAugkCOgAAbiI6OlpvvfWWJKmxsVGlpaVqb29XSUmJo6Pt5eWlDRs2SJJ+//13NTQ0qL6+XjU1NZKk9vZ23blzRydOnFB2dnaX648fP17jx4+XJNXW1ioyMlJBQUGOrr3ZbFZSUpKqqqoeyHgBAOhuCOgAALgJHx8fDR48WJI0ePBgxcbGKiUlRbNnz9auXbvUu3dvSdKBAwf03nvvqb6+Xj4+Pho0aJB8fHwk3Zsm39zcLMMw1KdPn//3vW7cuKGGhoY/dezvu337try9vf/iEQIA0L0R0AEAcFN9+vRRfn6+srOztXz5chUVFenixYvKysrSmDFjtHbtWgUHB0uStmzZogMHDki6txq8yWTS9evXu1zPZrOptrZWQ4YMkZ+fn+Li4rR48eL/8729vLz+u4MDAKAbYhV3AADc2Lhx4zRixAjt3r1bhw8f1vHjx3X37l3NnTvXEc4lOcK5YRjy8fFRZGSk9u7d2+VaBw8eVHp6uq5evaq4uDhduHBBoaGhGjx4sOOnqqpK27dvl4eHxwMdJwAA3QEBHQAAN7d06VJ5enrq3XffVXR0tCwWiwoLC3Xo0CHV1NQoOztb+/btkyTdunVLkjR//nydOHFCCxcu1DfffKPKykotW7ZMo0aNUmRkpNLS0tTZ2am0tDRVV1ertrZWeXl52rx5s8LCwpw4WgAAXBcBHQAANxcWFqaZM2fq559/Vk1NjYqKitTY2KjMzEzl5+dLkj777DOZTCZ9++23kqRRo0Zp7dq1+vXXX5WVlaXi4mJNmDBBRUVFkqSgoCBVVFTIarWqoKBAGRkZ+vHHH7V8+XKlpaU5a6gAALg0k2EYhrOLAAAAAADA3dFBBwAAAADABRDQAQAAAABwAQR0AAAAAABcAAEdAAAAAAAXQEAHAAAAAMAFENABAAAAAHABBHQAAAAAAFwAAR0AAAAAABdAQAcAAAAAwAUQ0AEAAAAAcAEEdAAAAAAAXAABHQAAAAAAF/A/TIlWRhfYapgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Setting the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Creating a boxplot to show the relationship between race and decile_score\n",
    "plt.figure(figsize=(12, 6))\n",
    "boxplot = sns.boxplot(x='race', y='decile_score', data=data)\n",
    "plt.title('Relation between Decile Score and Race')\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Decile Score')\n",
    "plt.xticks(rotation=45)  # Rotate labels for better readability\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364d98e-7130-4fe2-9df9-71405a9d645b",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871e3a9f-426c-4545-8a65-91df1b1b03dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>score_text</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  c_charge_degree race  score_text  priors_count  two_year_recid  \\\n",
       "1   34                0    0           0             0               1   \n",
       "2   24                0    0           0             4               1   \n",
       "6   41                0    1           1            14               1   \n",
       "8   39                1    1           0             0               0   \n",
       "9   21                0    1           0             1               1   \n",
       "\n",
       "   is_violent_recid  length_of_stay  \n",
       "1                 1            10.0  \n",
       "2                 0             1.0  \n",
       "6                 0             6.0  \n",
       "8                 0             2.0  \n",
       "9                 1             0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecting Specific Columns:\n",
    "#This line creates a new DataFrame df by selecting specific columns from the original data DataFrame. \n",
    "#These columns include demographic, charge, and incarceration details.\n",
    "df = data[['age', 'c_charge_degree', 'race', 'score_text', 'priors_count',             \n",
    "           #'decile_score',\n",
    "           'two_year_recid', 'c_jail_in', 'c_jail_out', 'is_violent_recid']]\n",
    "\n",
    "\n",
    "#Filtering for Specific Races:This line restricts the dataset to only include rows where the race is either 'African-American' or 'Caucasian'.\n",
    "df = df.loc[df['race'].isin(('African-American', 'Caucasian'))]\n",
    "\n",
    "\n",
    "#Encoding Racial Categories:\n",
    "#Here, the race categories are converted into numeric values: 0 for 'African-American' and 1 for 'Caucasian'.\n",
    "df.loc[df[\"race\"] == \"African-American\", \"race\"] = 0\n",
    "df.loc[df[\"race\"] == \"Caucasian\", \"race\"] = 1\n",
    "\n",
    "# Filtering Charge Degrees and Score Text:\n",
    "#These lines exclude cases where the charge degree is 'O' (possibly other) and where the COMPAS score text is not available ('N/A').\n",
    "df = df.loc[df['c_charge_degree'] != 'O']\n",
    "df = df.loc[df['score_text'] != 'N/A']\n",
    "\n",
    "#Calculating Length of Stay:\n",
    "#This calculates the length of jail stay in days by subtracting the jail in-date from the jail out-date and converts the result into a number of days.\n",
    "df['length_of_stay'] = (df['c_jail_out'].apply(pd.to_datetime) - df['c_jail_in'].apply(pd.to_datetime)).dt.days\n",
    "\n",
    "#Cleaning Data:\n",
    "#The first line removes any rows where length_of_stay is missing. \n",
    "#The second line removes the original jail in and out dates now that length_of_stay has been calculated.\n",
    "df = df.dropna(subset = ['length_of_stay'])\n",
    "df = df.drop(columns=['c_jail_in', 'c_jail_out'])\n",
    "\n",
    "#Encoding Other Variables:\n",
    "#This encodes the charge degree and COMPAS score text as numerical categories for easier analysis in statistical or machine learning models.\n",
    "df = df.replace({'c_charge_degree': 'F'}, 0)\n",
    "df = df.replace({'c_charge_degree': 'M'}, 1)\n",
    "df = df.replace({'score_text': 'Low'}, 0)\n",
    "df = df.replace({'score_text': 'Medium'}, 1)\n",
    "df = df.replace({'score_text': 'High'}, 2)\n",
    "\n",
    "#Removing Duplicates:\n",
    "#This line removes duplicate rows, ensuring each entry in the DataFrame is unique.\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#Previewing the Data:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "180f5aca-f0aa-492b-a73b-d97e9c72f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Train/Test Split Function:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splitting the Dataset into Training and Remaining (Validation + Testing) Sets:\n",
    "df_train, df_rem = train_test_split(df,train_size=5/7.0)\n",
    "#Splitting the Remaining Data into Validation and Testing Sets:\n",
    "df_valid, df_test = train_test_split(df_rem, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a2221-43d6-4411-bb29-a00c03af9365",
   "metadata": {},
   "source": [
    "The validation set is often used to fine-tune the model parameters and prevent overfitting before final evaluation on the test set.This approach of splitting into three parts helps in developing a robust model by having distinct datasets for training, tuning, and final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9aaf6fb-a95c-486f-a384-e80f081ca7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#further subdivides the training, testing, and validation datasets into separate groups based on the race attribute. \n",
    "#Here, race has been encoded as 0 for 'African-American' and 1 for 'Caucasian'\n",
    "df_train_a = df_train[df_train['race'] == 0]\n",
    "df_train_c = df_train[df_train['race'] == 1]\n",
    "\n",
    "df_test_a = df_test[df_test['race'] == 0]\n",
    "df_test_c = df_test[df_test['race'] == 1]\n",
    "\n",
    "df_valid_a = df_valid[df_valid['race'] == 0]\n",
    "df_valid_c = df_valid[df_valid['race'] == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b2280d-795c-427f-9b7f-1b55f33c133e",
   "metadata": {},
   "source": [
    "By creating these subsets, you can analyze the data or train models specifically to investigate or address disparities in outcomes or model performances between these two racial groups. This approach is often used in fairness analyses or when creating models that need to be sensitive to the potential biases that might affect different demographic groups differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaeb4fe5-f06e-4774-aa37-724d23134305",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a = df_train_a.drop(columns = ['two_year_recid', 'race'])\n",
    "X_train_c = df_train_c.drop(columns = ['two_year_recid', 'race'])\n",
    "Y_train_a = df_train_a['two_year_recid']\n",
    "Y_train_c = df_train_c['two_year_recid']\n",
    "S_train_a = df_train_a['race']\n",
    "S_train_c = df_train_c['race']\n",
    "\n",
    "X_test_a = df_test_a.drop(columns = ['two_year_recid', 'race'])\n",
    "X_test_c = df_test_c.drop(columns = ['two_year_recid', 'race'])\n",
    "Y_test_a = df_test_a['two_year_recid']\n",
    "Y_test_c = df_test_c['two_year_recid']\n",
    "S_test_a = df_test_a['race']\n",
    "S_test_c = df_test_c['race']\n",
    "\n",
    "X_valid_a = df_valid_a.drop(columns = ['two_year_recid', 'race'])\n",
    "X_valid_c = df_valid_c.drop(columns = ['two_year_recid', 'race'])\n",
    "Y_valid_a = df_valid_a['two_year_recid']\n",
    "Y_valid_c = df_valid_c['two_year_recid']\n",
    "S_valid_a = df_valid_a['race']\n",
    "S_valid_c = df_valid_c['race']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a6b5c-7532-44aa-af19-0ddc7f2f9b09",
   "metadata": {},
   "source": [
    "### Training Set Preparation\r\n",
    "Features (X_train_a, X_train_c): These dataframes store the input features for each race by dropping the target variable two_year_recid and the sensitive attribute race. This ensures the models trained on these sets are not directly influenced by the race of the individuals\n",
    "\n",
    "\n",
    "Targets (Y_train_a, Y_train_c): These are the target variables (labels) for the models, indicating whether the individual recidivated within two years\n",
    "\n",
    "\n",
    "Sensitive Attributes (S_train_a, S_train_c): ): Although dropped from the features, you keep track of the sensitive attribute 'race' separately, possibly for analysis of model fairness or bias post-traini\n",
    "oups.\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97085678-281f-436f-ae8e-716823fcaf4e",
   "metadata": {},
   "source": [
    "### Testing Set Preparation\n",
    "Features (X_test_a, X_test_c): Similar to the training sets, these feature sets are prepared by excluding the target and race variables.\n",
    "\n",
    "Targets (Y_test_a, Y_test_c): These contain the actual outcomes used to evaluate model performance after training.\n",
    "\n",
    "Sensitive Attributes (S_test_a, S_test_c): Retaining the sensitive attribute separately for potentially assessing any bias in model predictions during testing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bb4352-6fbc-417a-8103-d4926ed1ed47",
   "metadata": {},
   "source": [
    "### Validation Set Preparation\n",
    "Features (X_valid_a, X_valid_c): Prepared identically to the training and testing sets, these features are used to fine-tune the model parameters.\n",
    "\n",
    "Targets (Y_valid_a, Y_valid_c): Used to validate the model's predictions and adjust for overfitting.\n",
    "\n",
    "Sensitive Attributes (S_valid_a, S_valid_c): Kept for evaluating how the model's predictions might vary with the race of the individuals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5514d-a2ac-4bf0-b4ae-9da998d40a14",
   "metadata": {},
   "source": [
    "This structured approach allows you to conduct detailed analyses of model performance and fairness across different racial groups, a critical aspect when working with sensitive and potentially biased data. It enables the detection and mitigation of disparate impacts that the model might have on different subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b3a81be-0ed0-4009-933c-84579cca879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "\n",
    "train_X_c=t.tensor(np.array(X_train_c).astype('float32'))\n",
    "train_Y_c=t.from_numpy(np.array(Y_train_c).astype('float32')).reshape(X_train_c.shape[0],1)\n",
    "train_X_a=t.tensor(np.array(X_train_a).astype('float32'))\n",
    "train_Y_a=t.from_numpy(np.array(Y_train_a).astype('float32')).reshape(X_train_a.shape[0],1)\n",
    "\n",
    "valid_X_c=t.tensor(np.array(X_valid_c).astype('float32'))\n",
    "valid_Y_c=t.from_numpy(np.array(Y_valid_c).astype('float32')).reshape(X_valid_c.shape[0],1)\n",
    "valid_X_a=t.tensor(np.array(X_valid_a).astype('float32'))\n",
    "valid_Y_a=t.from_numpy(np.array(Y_valid_a).astype('float32')).reshape(X_valid_a.shape[0],1)\n",
    "\n",
    "test_X_c=t.tensor(np.array(X_test_c).astype('float32'))\n",
    "test_Y_c=t.from_numpy(np.array(Y_test_c).astype('float32')).reshape(X_test_c.shape[0],1)\n",
    "test_X_a=t.tensor(np.array(X_test_a).astype('float32'))\n",
    "test_Y_a=t.from_numpy(np.array(Y_test_a).astype('float32')).reshape(X_test_a.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f7bda-e419-4c6d-be46-41c18510c34c",
   "metadata": {},
   "source": [
    "Using PyTorch, a powerful deep learning framework, to convert your training, validation, and test datasets into tensors. These tensors are then used to train and evaluate deep learning models. Hereâ€™s a breakdown of what each line of the code does:\r",
    "architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed53e36-af93-4f06-9b89-a7f12447aa0a",
   "metadata": {},
   "source": [
    "### Conversion to Tensors\n",
    "\n",
    "Features (X):\n",
    " train_X_c, train_X_a, valid_X_c, valid_X_a, test_X_c, test_X_a: These lines convert the feature dataframes for Caucasian and African-American groups into PyTorch tensors of type float32. This conversion is essential for neural network models in PyTorch, as they operate on tensors.\n",
    "\n",
    "Targets (Y):\n",
    " train_Y_c, train_Y_a, valid_Y_c, valid_Y_a, test_Y_c, test_Y_a: These lines convert the target arrays into PyTorch tensors and reshape them to have the shape [n_samples, 1], where n_samples is the number of samples in each respective set. This reshaping is typical for target variables in many machine learning tasks, particularly in supervised learning where the model predicts a single value per instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7bf0cb-834d-48b7-a493-b05716078ff1",
   "metadata": {},
   "source": [
    "### Utilization in PyTorch\n",
    "\n",
    "These tensors (train_X_c, train_Y_c, etc.) are now ready to be used in a machine learning model using PyTorch. For instance, they can be fed into a neural network for binary classification (predicting two_year_recid).\n",
    "\n",
    "The use of float32 data type is aligned with the standard data type used in neural networks for efficiency and performance reasons.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e7cc7f-f968-407a-a92d-05e592f3e839",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "Model Definition: Define your neural network architecture using PyTorch's module system (nn.Module).\n",
    "\n",
    "Training Loop: Implement the training loop where you will feed these tensors into your model, calculate the loss (e.g., using binary cross-entropy), and update the model's weights using an optimizer (e.g., Adam or SGD).\n",
    "\n",
    "Evaluation: Use the validation and test sets to evaluate your model's performance and tune hyperparameters or make adjustments to the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07322067-1537-4285-9c85-a6c50ec63d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)  # Output is 1 since it's binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))  # Sigmoid activation to output probabilities\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6296ad5-36ae-46c4-be47-0503a0829986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming input features have a certain size, replace with actual number of features\n",
    "input_size = train_X_a.shape[1]  \n",
    "model_a = LogisticRegressionModel(input_size)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model_a.parameters(), lr=0.01)  # Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc806d59-b238-43a8-8b10-281c34820ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.8418\n",
      "Epoch [20/100], Loss: 1.0667\n",
      "Epoch [30/100], Loss: 1.0379\n",
      "Epoch [40/100], Loss: 1.5384\n",
      "Epoch [50/100], Loss: 1.0173\n",
      "Epoch [60/100], Loss: 1.4431\n",
      "Epoch [70/100], Loss: 1.0052\n",
      "Epoch [80/100], Loss: 1.3540\n",
      "Epoch [90/100], Loss: 1.0018\n",
      "Epoch [100/100], Loss: 1.3457\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, train_X, train_Y, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()  # Clear the gradients\n",
    "        outputs = model(train_X)  # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, train_Y)  # Calculate loss\n",
    "        loss.backward()  # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        optimizer.step()  # Update weights based on gradients\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Train the model\n",
    "train_model(model_a, criterion, optimizer, train_X_a, train_Y_a.view(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d190ef2b-069a-48dd-b754-3c6dc1a4bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the African-American validation group: 67.21%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X, Y):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        predicted = model(X)\n",
    "        predicted_classes = (predicted >= 0.5).float()  # Convert probabilities to 0 or 1\n",
    "        correct_count = (predicted_classes == Y).sum().float()\n",
    "        accuracy = correct_count / Y.shape[0]\n",
    "        return accuracy\n",
    "\n",
    "# Calculate accuracy on validation set\n",
    "accuracy_a = evaluate_model(model_a, valid_X_a, valid_Y_a)\n",
    "print(f'Accuracy of the model on the African-American validation group: {accuracy_a.item()*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51744981-c476-4a44-b641-5fd2f53f246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_X_c.shape[1]\n",
    "model_c = LogisticRegressionModel(input_size)\n",
    "\n",
    "# Loss function\n",
    "criterion_c = nn.BCELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer_c = optim.SGD(model_c.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28386cc6-07bf-4f78-83a8-5839ddb560d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.6205\n",
      "Epoch [20/100], Loss: 2.2805\n",
      "Epoch [30/100], Loss: 1.2028\n",
      "Epoch [40/100], Loss: 2.1240\n",
      "Epoch [50/100], Loss: 1.1914\n",
      "Epoch [60/100], Loss: 2.0982\n",
      "Epoch [70/100], Loss: 1.1809\n",
      "Epoch [80/100], Loss: 1.9164\n",
      "Epoch [90/100], Loss: 1.1980\n",
      "Epoch [100/100], Loss: 1.8980\n"
     ]
    }
   ],
   "source": [
    "train_model(model_c, criterion_c, optimizer_c, train_X_c, train_Y_c.view(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1823c730-05da-4580-b073-f082e38a9258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the Caucasian validation group: 57.99%\n"
     ]
    }
   ],
   "source": [
    "accuracy_c = evaluate_model(model_c, valid_X_c, valid_Y_c)\n",
    "print(f'Accuracy of the model on the Caucasian validation group: {accuracy_c.item()*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72f3dd3f-1133-411c-8eb9-923f358c3654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  tensor(0.6260)\n",
      "Validation calibration score:  tensor(0.0922)\n"
     ]
    }
   ],
   "source": [
    "# Accuracy in general and Calibration\n",
    "accuracy = (accuracy_a+accuracy_c)/2\n",
    "calibration = abs(accuracy_a - accuracy_c)\n",
    "\n",
    "print(\"Validation accuracy: \", accuracy)\n",
    "print(\"Validation calibration score: \", calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6505945-0add-410f-ba3c-ae52fedf0871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for African-American group: 63.45%\n",
      "Test Accuracy for Caucasian group: 57.34%\n",
      "Average Test Accuracy: 60.40%\n",
      "Test Calibration Score: 6.11%\n"
     ]
    }
   ],
   "source": [
    "# Assuming the models are PyTorch models named model_a and model_c\n",
    "\n",
    "# Evaluate the model on the test set for African-American group\n",
    "accuracy_a_test = evaluate_model(model_a, test_X_a, test_Y_a)\n",
    "print(f'Test Accuracy for African-American group: {accuracy_a_test.item()*100:.2f}%')\n",
    "\n",
    "# Evaluate the model on the test set for Caucasian group\n",
    "accuracy_c_test = evaluate_model(model_c, test_X_c, test_Y_c)\n",
    "print(f'Test Accuracy for Caucasian group: {accuracy_c_test.item()*100:.2f}%')\n",
    "\n",
    "# Calculate average test accuracy and test calibration score\n",
    "average_test_accuracy = (accuracy_a_test + accuracy_c_test) / 2\n",
    "test_calibration_score = abs(accuracy_a_test - accuracy_c_test)\n",
    "print(f\"Average Test Accuracy: {average_test_accuracy.item()*100:.2f}%\")\n",
    "print(f\"Test Calibration Score: {test_calibration_score.item()*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ce64668-916c-42c3-9559-048c08e6836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Model_c, Model_a, df_c_X_train, df_c_y_train, df_a_X_train, df_a_y_train):\n",
    "    yc_pred = (Model_c(df_c_X_train) >= 0.5)\n",
    "    ya_pred = (Model_a(df_a_X_train) >= 0.5)\n",
    "    accu_c = t.sum(yc_pred.flatten() == df_c_y_train.flatten()) / df_c_X_train.shape[0]\n",
    "    accu_a = t.sum(ya_pred.flatten() == df_a_y_train.flatten()) / df_a_X_train.shape[0]\n",
    "\n",
    "    accuracy = (accu_c + accu_a) / 2\n",
    "    calibration = abs(accu_c - accu_a)\n",
    "\n",
    "    print(\"Accuracy : {:.3f}%\".format(accuracy.item() * 100))\n",
    "    print(\"Calibration : {:.3f}%\".format(calibration.item() * 100))\n",
    "\n",
    "    return round(accuracy.item(), 4), round(calibration.item(), 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5022bb28-faae-45ee-a286-eb2039d615cd",
   "metadata": {},
   "source": [
    "Function 'accuracy' is designed to calculate the accuracy and calibration scores of two PyTorch models, one trained on data from the Caucasian group (Model_c) and the other on data from the African-American group (Model_a). The function takes these models and their respective training datasets as inputs. Here's an analysis and a slight correction to improve the function:\n",
    "\n",
    "### Function Breakdown\n",
    "### Prediction:\n",
    "\n",
    "yc_pred and ya_pred are tensors of booleans where predictions are determined by whether the model outputs are greater than or equal to 0.5. This is typical for binary classification tasks using logistic regression where the sigmoid function's output is interpreted as a probability.\n",
    "### Accuracy Calculation:\n",
    "\n",
    "accu_c and accu_a: These lines calculate the accuracy for each group by comparing the predicted labels to the true labels (df_c_y_train and df_a_y_train). The comparison generates a Boolean tensor, and taking the sum of this tensor gives the number of correct predictions. Dividing by the total number of samples (df_c_X_train.shape[0] or df_a_X_train.shape[0]) yields the accuracy as a proportion.\n",
    "### Overall Accuracy and Calibration:\n",
    "\n",
    "The average accuracy (accuracy) is calculated by averaging accu_c and accu_a.\n",
    "Calibration (calibration) is computed as the absolute difference between accu_c and accu_a, which measures how similarly the two models perform across the different racial groups. This is an important metric in fairness analysis.\n",
    "### Returning Results:\n",
    "\n",
    "The function returns the rounded values of accuracy and calibration to four decimal places.\n",
    "Suggested Correction and Improvement\n",
    "The print statements at the end of your function will never execute because they are placed after a return statement. If you want these printouts to occur every time the function is called, you should move them before the return statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4a462-7b64-4919-aa47-f09f244899f8",
   "metadata": {},
   "source": [
    "# Logistic Regression with Prejudice Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d977bcda-25db-41b5-8f8a-25504a276828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "\n",
    "class PRLoss(nn.Module):  # Inherit from nn.Module\n",
    "    def __init__(self, eta=1.0):\n",
    "        super(PRLoss, self).__init__()\n",
    "        self.eta = eta\n",
    "\n",
    "    def forward(self, output_c, output_a):\n",
    "        epsilon = 1e-8  # Small number to prevent division by zero or log(0)\n",
    "        \n",
    "        N_cau = t.tensor(output_c.shape[0], dtype=t.float32)\n",
    "        N_aa = t.tensor(output_a.shape[0], dtype=t.float32)\n",
    "        Dxisi = t.stack((N_aa, N_cau))  # Stack along a new dimension\n",
    "\n",
    "        y_pred_cau = t.sum(output_c)\n",
    "        y_pred_aa = t.sum(output_a)\n",
    "        P_ys = t.stack((y_pred_aa, y_pred_cau)) / Dxisi\n",
    "\n",
    "        total = t.cat((output_c, output_a), 0)\n",
    "        P_y = t.sum(total) / (output_c.shape[0] + output_a.shape[0])\n",
    "\n",
    "        P_s1y1 = t.log(P_ys[1] / (P_y + epsilon) + epsilon)\n",
    "        P_s1y0 = t.log((1 - P_ys[1]) / (1 - P_y + epsilon) + epsilon)\n",
    "        P_s0y1 = t.log(P_ys[0] / (P_y + epsilon) + epsilon)\n",
    "        P_s0y0 = t.log((1 - P_ys[0]) / (1 - P_y + epsilon) + epsilon)\n",
    "\n",
    "        PI_s1y1 = output_c * P_s1y1\n",
    "        PI_s1y0 = (1 - output_c) * P_s1y0\n",
    "        PI_s0y1 = output_a * P_s0y1\n",
    "        PI_s0y0 = (1 - output_a) * P_s0y0\n",
    "\n",
    "        PI = t.sum(PI_s1y1) + t.sum(PI_s1y0) + t.sum(PI_s0y1) + t.sum(PI_s0y0)\n",
    "        return self.eta * PI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98a0cc-4ca9-4ee2-af9c-2e2787ede97e",
   "metadata": {},
   "source": [
    "### Overview of the Class:\n",
    "Initialization (__init__):\n",
    "\n",
    "eta: A hyperparameter that scales the penalty.\n",
    "Forward Method (forward):\n",
    "\n",
    "Takes output_c and output_a as inputs, which represent model outputs for the Caucasian and African-American groups, respectively.\n",
    "Implements equations to calculate the mutual information between the outputs and the sensitive attribute (race), aiming to penalize predictions that result in disparate impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dd5828a-a64e-4e80-a123-c9989b827798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self,data):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.w = nn.Linear(data.shape[1], out_features=1, bias=True)\n",
    "        self.sigmod = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        w = self.w(x)\n",
    "        output = self.sigmod(w)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeedc2a-3b5f-4af7-8494-3181cc909617",
   "metadata": {},
   "source": [
    "This class defines a simple logistic regression model using PyTorchâ€™s neural network module (nn.Module)\n",
    "\n",
    "### Class Overview\n",
    "__init__ Method:\n",
    "\n",
    "Initializes the model by setting up a linear layer with weights (self.w) and a bias. The input feature dimension is determined by data.shape[1], which should be the number of features in your dataset.\n",
    "A sigmoid activation function (self.sigmod) is defined to map the linear layer's output to a probability (0 to 1), suitable for binary classification.\n",
    "\n",
    "\n",
    "forward Method:\n",
    "\n",
    "Defines the forward pass of the model. It takes an input tensor x, applies the linear transformation, and then applies the sigmoid function to produce the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "880a935c-04ad-43ac-adb4-366a463a2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRLR():\n",
    "    def __init__(self, eta = 1, iters = 100, step = 0.01):\n",
    "        super(PRLR, self).__init__()\n",
    "        self.eta = eta\n",
    "        self.step = step\n",
    "        self.iters = iters\n",
    "\n",
    "    def fit(self, X_train_c, Y_train_c, X_train_a, Y_train_a, \n",
    "            X_valid_c, Y_valid_c, X_valid_a, Y_valid_a,\n",
    "            X_test_c, Y_test_c, X_test_a, Y_test_a):\n",
    "        modela = LogisticRegression(X_train_a)      # African-American\n",
    "        modelc = LogisticRegression(X_train_c)      # Caucasian\n",
    "        loss = nn.BCELoss(reduction='sum')\n",
    "        iters = self.iters\n",
    "        PI_term = PRLoss(eta = self.eta)\n",
    "        #L2_optimizer = t.optim.Adam(list(np.abs(model0.parameters()) + np.abs(model1.parameters())), self.step, weight_decay = 1e-5)\n",
    "        L2_optimizer = t.optim.Adam(list(modela.parameters())+list(modelc.parameters()), self.step, weight_decay = 1e-5)\n",
    "        \n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for iter in range(iters):\n",
    "            modela.train()\n",
    "            modelc.train()\n",
    "            L2_optimizer.zero_grad()\n",
    "            \n",
    "            ## sigmoid probability and loss\n",
    "            output_a = modela(X_train_a)    # A-A\n",
    "            output_c = modelc(X_train_c)\n",
    "            # Loss_func is the sum of LogLoss and PI Loss\n",
    "            loss_function_train = loss(output_c, Y_train_c) + loss(output_a, Y_train_a) + PI_term.forward(output_c, output_a)\n",
    "            loss_function_train.backward()\n",
    "            L2_optimizer.step()\n",
    "            train_losses.append(loss_function_train)\n",
    "\n",
    "\n",
    "            output_a_valid = modela(X_valid_a)\n",
    "            output_c_valid = modelc(X_valid_c)\n",
    "            loss_function_val = loss(output_c_valid, Y_valid_c) + loss(output_a_valid, Y_valid_a) + PI_term.forward(output_c_valid, output_a_valid)\n",
    "\n",
    "            val_losses.append(loss_function_val)\n",
    "\n",
    "\n",
    "        modela.eval()\n",
    "        modelc.eval()\n",
    "        # accuracy\n",
    "        accu = accuracy(modelc,modela,X_train_c,Y_train_c,X_train_a,Y_train_a)\n",
    "        accu_val = accuracy(modelc,modela,X_valid_c,Y_valid_c,X_valid_a,Y_valid_a)\n",
    "        accu_test = accuracy(modelc,modela,X_test_c,Y_test_c,X_test_a,Y_test_a)\n",
    "        \n",
    "        # PI index\n",
    "        # pi_train = PI_term.forward(modela(X_train_a), modelc(X_train_c))\n",
    "        # pi_valid = PI_term.forward(modela(X_valid_a), modelc(X_valid_c))\n",
    "        # pi_test = PI_term.forward(modela(X_test_a), modelc(X_test_c))\n",
    "\n",
    "        return accu, accu_val, accu_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f3b99-5438-472d-98a2-66a7cef3035e",
   "metadata": {},
   "source": [
    " class PRLR is designed to implement a specific logistic regression training process, considering both traditional loss and a custom probabilistic loss (PRLoss) that seems to be aimed at enforcing some kind of fairness or parity constraint between two different groups (African-American and Caucasian). \n",
    "\n",
    "### Class Overview\r\n",
    "Initialization (__init__):\r\n",
    "\r\n",
    "Initializes hyperparameters such as the learning rate (step), number of iterations (iters), and a scaling factor (et\n",
    "\n",
    "\n",
    "a).\r\n",
    "fit Method:\r\n",
    "\r\n",
    "This method sets up and trains two logistic regression modelsâ€”one for each group. It integrates a standard binary cross-entropy loss (BCELoss) and the custom PRLoss to enforce fairness constraints during training.ining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "834ddb86-a4d0-4be3-a7c6-75e17ccbe910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 69.737%\n",
      "Calibration : 0.946%\n",
      "Accuracy : 72.892%\n",
      "Calibration : 3.521%\n",
      "Accuracy : 68.938%\n",
      "Calibration : 4.082%\n",
      "Accuracy : 69.370%\n",
      "Calibration : 1.771%\n",
      "Accuracy : 72.891%\n",
      "Calibration : 0.747%\n",
      "Accuracy : 69.977%\n",
      "Calibration : 3.402%\n",
      "Accuracy : 69.671%\n",
      "Calibration : 1.807%\n",
      "Accuracy : 71.966%\n",
      "Calibration : 1.207%\n",
      "Accuracy : 69.163%\n",
      "Calibration : 2.234%\n",
      "Accuracy : 69.646%\n",
      "Calibration : 2.040%\n",
      "Accuracy : 71.330%\n",
      "Calibration : 0.396%\n",
      "Accuracy : 68.993%\n",
      "Calibration : 3.273%\n",
      "Accuracy : 69.542%\n",
      "Calibration : 1.974%\n",
      "Accuracy : 71.041%\n",
      "Calibration : 0.280%\n",
      "Accuracy : 69.168%\n",
      "Calibration : 3.623%\n",
      "Accuracy : 69.449%\n",
      "Calibration : 2.070%\n",
      "Accuracy : 70.404%\n",
      "Calibration : 0.531%\n",
      "Accuracy : 68.708%\n",
      "Calibration : 4.542%\n",
      "Accuracy : 69.494%\n",
      "Calibration : 2.161%\n",
      "Accuracy : 70.693%\n",
      "Calibration : 0.415%\n",
      "Accuracy : 68.768%\n",
      "Calibration : 5.122%\n",
      "Accuracy : 69.348%\n",
      "Calibration : 3.002%\n",
      "Accuracy : 70.463%\n",
      "Calibration : 1.435%\n",
      "Accuracy : 68.638%\n",
      "Calibration : 1.185%\n",
      "Accuracy : 69.325%\n",
      "Calibration : 2.956%\n",
      "Accuracy : 70.462%\n",
      "Calibration : 0.047%\n",
      "Accuracy : 68.588%\n",
      "Calibration : 3.383%\n",
      "Accuracy : 69.302%\n",
      "Calibration : 2.910%\n",
      "Accuracy : 70.636%\n",
      "Calibration : 0.395%\n",
      "Accuracy : 68.588%\n",
      "Calibration : 3.383%\n"
     ]
    }
   ],
   "source": [
    "eta_value = [0.0,1.0,2.0,3.0,4.0,5.0,10.0,15.0,20.0,25.0]\n",
    "accur = list()\n",
    "accur_val = list()\n",
    "accur_test = list()\n",
    "# PI_train = list()\n",
    "# PI_val = list()\n",
    "# PI_test = list()\n",
    "for i in range(0,len(eta_value)):\n",
    "    #print(\"Theta Value: %d\" % eta_value[e])\n",
    "    PR = PRLR(eta = eta_value[i], iters = 3000, step = 0.01)\n",
    "    accur_eta,accur_val_eta,accur_test_eta = PR.fit(train_X_c,train_Y_c,train_X_a,train_Y_a,\n",
    "                                                    valid_X_c,valid_Y_c,valid_X_a,valid_Y_a,\n",
    "                                                    test_X_c,test_Y_c,test_X_a,test_Y_a)\n",
    "    accur.append(accur_eta)\n",
    "    accur_val.append(accur_val_eta)\n",
    "    accur_test.append(accur_test_eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca35750-34de-4770-b618-2c28ebca1cfd",
   "metadata": {},
   "source": [
    "### Overview\n",
    "eta_value: A list of different values for the eta parameter.\n",
    "Training Loop:\n",
    "For each eta value, you initialize a PRLR model and train it using the fit method.\n",
    "The accuracies for training, validation, and test sets are stored in respective lists for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "387ac0bb-d634-4e3b-b8f9-d868c7d0c9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6978, 0.0104),\n",
       " (0.6937, 0.0177),\n",
       " (0.6964, 0.0188),\n",
       " (0.6965, 0.0204),\n",
       " (0.6957, 0.0202),\n",
       " (0.6962, 0.0199),\n",
       " (0.6957, 0.0202),\n",
       " (0.6948, 0.0228),\n",
       " (0.6937, 0.0277),\n",
       " (0.695, 0.026)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb64f8c7-79d6-4c60-9d82-34173677fca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7289, 0.0352),\n",
       " (0.7289, 0.0075),\n",
       " (0.7197, 0.0121),\n",
       " (0.7133, 0.004),\n",
       " (0.7087, 0.0007),\n",
       " (0.704, 0.0053),\n",
       " (0.7017, 0.0007),\n",
       " (0.7017, 0.0007),\n",
       " (0.7035, 0.0028),\n",
       " (0.7029, 0.003)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation\n",
    "accur_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bc9a271-feda-4543-b1ee-cb277a2ddef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6894, 0.0408),\n",
       " (0.6998, 0.034),\n",
       " (0.6934, 0.0258),\n",
       " (0.6899, 0.0327),\n",
       " (0.6894, 0.0408),\n",
       " (0.6871, 0.0454),\n",
       " (0.6882, 0.0431),\n",
       " (0.6865, 0.0396),\n",
       " (0.683, 0.0326),\n",
       " (0.6847, 0.0361)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "accur_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e78c5f-5f67-4e52-a603-c37904576a95",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "308a3e48-880b-4a2d-a3f9-7bbe88f824d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.6967, 0.0181), (0.7197, 0.0121), (0.6916, 0.0223))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PR_eta2 = PRLR(eta = 2.0, iters = 3000, step = 0.01)\n",
    "PR_eta2.fit(train_X_c,train_Y_c,train_X_a,train_Y_a,\n",
    "                                                    valid_X_c,valid_Y_c,valid_X_a,valid_Y_a,\n",
    "                                                    test_X_c,test_Y_c,test_X_a,test_Y_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801fc35d-2bb1-4ed9-8c2c-622d2230fd35",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "Hereâ€™s what happens when you execute this code:\n",
    "\n",
    "Model Initialization:\n",
    "\n",
    "A new instance of PRLR is created with eta = 2.0, iters = 3000, and step = 0.01. These parameters will control the training process, where eta influences the weight of the fairness term in your loss function.\n",
    "Model Training:\n",
    "\n",
    "The fit method will be executed, which entails:\n",
    "Training two logistic regression models for the two groups (Caucasian and African-American) over 3000 iterations.\n",
    "Using a learning rate (step) of 0.01 to update the model parameters.\n",
    "Applying both the binary cross-entropy loss and your custom PRLoss designed to adjust for fairness based on the eta value.\n",
    "Return Values:\n",
    "\n",
    "The method will return the training, validation, and testing accuracies. Make sure to capture these returned values if you want to analyze or report them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaeacc9-7780-4830-bef7-7272685dc978",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc6fcb-439a-448e-b546-3061a0c2882f",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/sony/nnabla-examples/blob/master/interactive-demos/prejudice_remover_regularizer.ipynb#scrollTo=r45NcxtY6OzB"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
